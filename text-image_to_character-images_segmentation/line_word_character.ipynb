{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "# import time\n",
    "# import multiprocessing\n",
    "# from functools import wraps\n",
    "# import diplib as dip\n",
    "# from skimage import img_as_ubyte\n",
    "# from utils.preprocess import resize\n",
    "# from skimage.filters import threshold_otsu\n",
    "# from utils.zhangSuenThinning import zhangSuen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vishwaksena_dingari/Documents/A Printed Character Recognition System for Meetei-Mayek Script Using Transfer Learning/text-image_to_character-images_segmentation\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPadding(image, all=None):\n",
    "    '''\n",
    "    - ``Input``: an image\n",
    "    - ``Output``:\n",
    "        - add padding top: 10, bottom: 20 - ((height + top) % 10), left: 10, right: 20 - ((width + left) % 10)\n",
    "        - so that the image can be divided into 10 equal parts vertically\n",
    "    '''\n",
    "    image = np.asarray(image)\n",
    "    height, width, channels = image.shape\n",
    "    # print(height, width, channels)\n",
    "    image = Image.fromarray(image)\n",
    "    if all == None:\n",
    "        top = 10\n",
    "        bottom = 20 - ((height+top) % 10)\n",
    "        left = 10\n",
    "        right = 20 - ((width+left) % 10)\n",
    "    else: top, right, bottom, left = all, all, all, all\n",
    "    new_width = width + left + right\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(image.mode, (new_width, new_height), (255, 255, 255))\n",
    "    result.paste(image, (left, top))\n",
    "    result = np.asarray(result)\n",
    "    # cv2.imshow('result', result)\n",
    "    # cv2.waitKey(0)\n",
    "    # print(result.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePadding(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, binary_image = cv2.threshold(\n",
    "        gray, 0, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY_INV\n",
    "    )\n",
    "    for i in range(4):\n",
    "        while sum(binary_image[0]) == 0:\n",
    "            image = image[1:]\n",
    "            binary_image = binary_image[1:]\n",
    "        image = np.rot90(image)\n",
    "        binary_image = np.rot90(binary_image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempDisplay(dict_):\n",
    "    \"\"\"\n",
    "    - `Input`: dictionary\n",
    "        - ``key``: name for the image to be displayed\n",
    "        - ``value``: image to be displayed\n",
    "    - `Output`: a matplotlib plot with the all the images in the dictionary in one image\n",
    "    \"\"\"\n",
    "    rows = int(math.sqrt(len(dict_)))\n",
    "    cols = math.ceil(len(dict_)/rows)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    i = 1\n",
    "    for key in dict_:\n",
    "        fig.add_subplot(rows, cols, i)\n",
    "        i = i + 1\n",
    "        plt.imshow(dict_[key])\n",
    "        plt.axis('off')\n",
    "        plt.title(str(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(pixel_values, original_image, rotate=False):\n",
    "    '''\n",
    "    - `Input`: \n",
    "        - ``pixel_values``: vertical pixel values range [from, to] to be cropped\n",
    "        - ``original_image``: image from which the cropped images are needed\n",
    "        - ``rotate``: if the image is to be rotated or not before the cropping (used for word segmentation form the line images)\n",
    "    - `Output`: cropped images from the ``original_image``\n",
    "    '''\n",
    "    image = original_image\n",
    "    if rotate:\n",
    "        image = np.rot90(image, 3)\n",
    "    cropped_images = []\n",
    "    h, w = image.shape[:2]\n",
    "    # dp = {}\n",
    "    for i in range(len(pixel_values)):\n",
    "        crop_image = image[pixel_values[i][0]:pixel_values[i][1], 0:w]\n",
    "        # dp[i] = crop_image\n",
    "        if rotate:\n",
    "            cropped_images.append(np.rot90(crop_image))\n",
    "        else:\n",
    "            cropped_images.append(crop_image)\n",
    "    # tempDisplay(dp)\n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# def imageContrast(image):\n",
    "#     image_contrast = np.zeros(image.shape, image.dtype)\n",
    "#     alpha = 1.1  # Simple contrast control and alpha value [1.0 - 3.0]\n",
    "#     beta = 5    # Simple brightness control and beta value [0 - 100]\n",
    "#     for y in range(image.shape[0]):\n",
    "#         for x in range(image.shape[1]):\n",
    "#             for c in range(image.shape[2]):\n",
    "#                 image_contrast[y, x, c] = np.clip(alpha * image[y, x, c] + beta, 0, 255)\n",
    "#     return image_contrast\n",
    "def imageContrast(image, alpha=1.1, beta=5):\n",
    "    # Convert the input image to a float32 array for better precision\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Apply the contrast and brightness adjustments using NumPy functions\n",
    "    image_contrast = np.clip(alpha * image + beta, 0, 255).astype(np.uint8)\n",
    "\n",
    "    image = Image.fromarray(image_contrast)\n",
    "\n",
    "    new_image = image\n",
    "\n",
    "    filter = ImageEnhance.Contrast(new_image)\n",
    "    new_image = filter.enhance(1.25)\n",
    "\n",
    "    filter = ImageEnhance.Sharpness(new_image)\n",
    "    new_image = filter.enhance(1.25)\n",
    "    \n",
    "    new_image = np.asarray(new_image)\n",
    "    \n",
    "    # cv2.imwrite(\"contrast.jpg\", new_image)\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(image, line_segmentation=False, word_segmentation=False, letter_segmentation=False):\n",
    "    \"\"\"\n",
    "    - `Input`:\n",
    "        - ``image``: image to be segmented\n",
    "        - ``rotate``: ``bool`` if the image is to be rotated or not (used for word segmentation form the line images)\n",
    "    - `Output`: vertical pixel values range [from, to] to be cropped \n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    ret, image = cv2.threshold(\n",
    "        image, 128, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # ret, image = cv2.threshold(image, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # ret, image = cv2.threshold(image, np.mean(image), 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # rect_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 4))\n",
    "    rect_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 2))\n",
    "    \n",
    "    \n",
    "    if line_segmentation:\n",
    "        line_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 1))\n",
    "        image = cv2.erode(image, rect_kernel_2, iterations=1)\n",
    "        image = cv2.dilate(image, line_kernel, iterations=1)\n",
    "        # cv2.imwrite(\"temp.jpg\", image)\n",
    "        \n",
    "    if word_segmentation:\n",
    "        image = np.rot90(image, 3)    \n",
    "        # para_image = cv2.dilate(image, rect_kernel_2, iterations=6)\n",
    "        image = cv2.dilate(image, rect_kernel_2, iterations=4)\n",
    "        # cv2.imshow(\"image\", image)\n",
    "        # cv2.waitKey(0)\n",
    "        # image = word_image\n",
    "    \n",
    "    if letter_segmentation:\n",
    "        image = np.rot90(image, 3)\n",
    "        # cv2.imshow(\"image\", image)\n",
    "        # cv2.waitKey(0)\n",
    "        # letter_kernel_10 = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "        # letter_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "        # image = cv2.erode(image, letter_kernel_10, iterations=2)\n",
    "        # image = cv2.dilate(image, letter_kernel_2, iterations=2)\n",
    "        # image = cv2.dilate(image, rect_kernel_2, iterations=1)\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    pixel_values = []\n",
    "    temp = []\n",
    "    for i in range(1, h):\n",
    "        if len(temp) == 2:\n",
    "            pixel_values.append(temp)\n",
    "            temp = []\n",
    "        \n",
    "        if len(temp) == 0 and sum(image[i-1]) == 0 and sum(image[i]) != 0:\n",
    "            temp.append(i - 1)\n",
    "        \n",
    "        if len(temp) == 1 and sum(image[i-1]) != 0 and sum(image[i]) == 0:\n",
    "            temp.append(i + 1)\n",
    "\n",
    "    return pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vishwaksena_dingari/Documents/A Printed Character Recognition System for Meetei-Mayek Script Using Transfer Learning/text-image_to_character-images_segmentation/img/37.jpg\n"
     ]
    }
   ],
   "source": [
    "# 83\n",
    "# img_name = \"95.jpg\"\n",
    "# total 1437 not_good 50\n",
    "# img_name = \"zz.jpg\"\n",
    "# total 1257 not_good 32\n",
    "# img_name = \"185.jpg\"\n",
    "# total 216 not_good 23\n",
    "# img_name = \"0_0.jpg\"\n",
    "# total 98 not_good 18\n",
    "# img_name = \"0_1.jpg\"\n",
    "# total 89 not_good 14\n",
    "# img_name = \"0_3.jpg\"\n",
    "# total 83 not_good 5\n",
    "# img_name = \"0_4.jpg\"\n",
    "# total 87 not_good 8\n",
    "# img_name = \"0_5.jpg\"\n",
    "# total 102 not_good 24\n",
    "img_name = \"37.jpg\"\n",
    "# img_name = \"212_1.jpg\"\n",
    "IMAGE_PATH = f\"{os.getcwd()}/img/{img_name}\"\n",
    "print(IMAGE_PATH)\n",
    "ORIGINAL_IMAGE = cv2.imread(IMAGE_PATH)\n",
    "ORIGINAL_IMAGE = addPadding(ORIGINAL_IMAGE)\n",
    "ORIGINAL_IMAGE = imageContrast(ORIGINAL_IMAGE)\n",
    "\n",
    "\n",
    "\n",
    "# image = ORIGINAL_IMAGE\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "# _, binary_img = cv2.threshold(image, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "# _, binary_img = cv2.threshold(binary_img, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "# ORIGINAL_IMAGE = resize(ORIGINAL_IMAGE, 250)\n",
    "\n",
    "####\n",
    "# the following function can also be used for line segmentation\n",
    "# and a similar function can be used for word segmentation\n",
    "# def line_dilation(image):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     ret, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "#     rect_kernel_110 = cv2.getStructuringElement(cv2.MORPH_RECT, (500, 1))\n",
    "#     dilation = cv2.dilate(thresh, rect_kernel_110, iterations=1)\n",
    "#     return dilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = f\"{os.getcwd()}/temp\"\n",
    "folder_names = [\"lines\", \"words\", \"thin_words\", \"letters0\", \"letters1\", \"letters2\"]\n",
    "\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    if not os.path.exists(f\"{temp_path}/{folder_name}\"):\n",
    "        os.mkdir(f\"{temp_path}/{folder_name}\")\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    folder_path = f\"{temp_path}/{folder_name}\"\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = f\"{folder_path}/{file}\"\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = segmentation(ORIGINAL_IMAGE, line_segmentation=True)\n",
    "ARTICLE_LINES = cropImage(pixel_values, ORIGINAL_IMAGE)\n",
    "\n",
    "avg_height = 0\n",
    "for i, line in enumerate(ARTICLE_LINES):\n",
    "    # print(line.shape[0], end=\" \")\n",
    "    avg_height += line.shape[0]\n",
    "avg_height = avg_height / len(ARTICLE_LINES)\n",
    "\n",
    "NEW_ARTICLE_LINES = []\n",
    "for i, line in enumerate(ARTICLE_LINES):\n",
    "    if line.shape[0] < avg_height //  2:\n",
    "        NEW_ARTICLE_LINES[len(NEW_ARTICLE_LINES)-1] = np.vstack((NEW_ARTICLE_LINES[len(NEW_ARTICLE_LINES)-1], line))\n",
    "    else:\n",
    "        NEW_ARTICLE_LINES.append(line)\n",
    "ARTICLE_LINES = NEW_ARTICLE_LINES\n",
    "\n",
    "for i, line in enumerate(ARTICLE_LINES):\n",
    "    # tempDisplay({i: ARTICLE_LINES[i]})\n",
    "    cv2.imwrite(f\"{os.getcwd()}/temp/lines/{i}.jpg\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_WORDS = []\n",
    "for line in ARTICLE_LINES:\n",
    "    pixel_values = segmentation(line, word_segmentation=True)\n",
    "    words = cropImage(pixel_values, line, rotate=True)\n",
    "    # words = [resize(word, 2000) for word in words]\n",
    "    ARTICLE_WORDS.append(words)\n",
    "    # tempDisplay({i: words[i] for i in range(len(words))})\n",
    "\n",
    "\n",
    "# mh, mw = 0, 0\n",
    "# for line in ARTICLE_WORDS:\n",
    "#     for i, word in enumerate(line):\n",
    "#         mh, mw = max(mh, word.shape[0]), max(mw, word.shape[1])\n",
    "# print(mh, mw)\n",
    "\n",
    "line_count = 0\n",
    "for line in ARTICLE_WORDS:\n",
    "    # tempDisplay({i: word for i, word in enumerate(line)})\n",
    "    for word_count, word in enumerate(line):\n",
    "        cv2.imwrite(\n",
    "            f\"{os.getcwd()}/temp/words/{line_count}_{word_count}.jpg\", word)\n",
    "    line_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARTICLE_LETTERS = []\n",
    "# for line in ARTICLE_WORDS:\n",
    "#     temp_line = []\n",
    "#     for word in line:\n",
    "#         pixel_values = segmentation(word, letter_segmentation=True)\n",
    "#         letters = cropImage(pixel_values, word, True)\n",
    "#         # tempDisplay({i : letters[i] for i in range(len(letters))})\n",
    "#         temp_line.append(letters)\n",
    "#     ARTICLE_LETTERS.append(temp_line)\n",
    "\n",
    "\n",
    "# for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "#     for word_count, word in enumerate(line):\n",
    "#         # tempDisplay({i: letter for i, letter in enumerate(word)})\n",
    "#         for letter_count, letter in enumerate(word):\n",
    "#             cv2.imwrite(f\"{os.getcwd()}/temp/letters/{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = 1\n",
    "\n",
    "def word2Letters(image):\n",
    "    # image = resize(image, 500)\n",
    "    org_img = image.copy()\n",
    "    img_copy = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    ret, binary_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # _, binary_img = cv2.threshold(gray, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "    # _, binary_img = cv2.threshold(gray, np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # dist = cv2.distanceTransform(binary_img, cv2.DIST_C, 3)\n",
    "    # ret, sure_fg = cv2.threshold(dist, 0.15 * dist.max(), 255, cv2.THRESH_BINARY)\n",
    "    # sure_fg = sure_fg.astype(np.uint8)\n",
    "    # binary_img = sure_fg\n",
    "    \n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    # binary_img = cv2.erode(sure_fg, kernel, iterations=1)\n",
    "    \n",
    "    thinned_img = binary_img\n",
    "    # thinned_img = cv2.ximgproc.thinning(binary_img,  thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    # thinned_img = cv2.dilate(thinned_img, kernel, iterations=1)\n",
    "    \n",
    "    # thinned_img = zhangSuen(binary_img).astype(np.uint8)\n",
    "    # thinned_img*=255\n",
    "    \n",
    "    # binary_img = np.array(binary_img, dtype=np.uint8)\n",
    "    # binary_img = binary_img > 128\n",
    "    # thinned_img = dip.EuclideanSkeleton(binary_img, endPixelCondition='three neighbors')\n",
    "    # thinned_img = np.array(thinned_img, dtype=np.uint8)\n",
    "    # thinned_img *= 255\n",
    "    \n",
    "    \n",
    "    # global cc\n",
    "    # cv2.imwrite(f\"{os.getcwd()}/temp/thin_words/{cc}.jpg\", thinned_img)\n",
    "    # cc += 1\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        thinned_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "    cropped_images = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # rect = cv2.rectangle(img_copy, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "        x1, y1, x2, y2 = x - 2, y - 2, x + w + 2, y + h + 2\n",
    "        # x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "        cropped = org_img[y1 : y2, x1 : x2]\n",
    "        cropped_images.append(cropped)\n",
    "    return cropped_images\n",
    "    \n",
    "    \n",
    "    # _, img = cv2.threshold(thinned_img, 75, 255, cv2.THRESH_BINARY_INV)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    # pixel_values = segmentation(img, letter_segmentation=True)\n",
    "    # return pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_LETTERS = []\n",
    "for line in ARTICLE_WORDS:\n",
    "    temp_line = []\n",
    "    for word in line:\n",
    "        word = addPadding(word, 2)\n",
    "        # pixel_values = word2Letters(word)\n",
    "        # letters = cropImage(pixel_values, word, True)\n",
    "        letters = word2Letters(word)\n",
    "        temp_line.append(letters)\n",
    "        # temp_line.append([removePadding(letter) for letter in letters])\n",
    "    ARTICLE_LETTERS.append(temp_line)\n",
    "\n",
    "\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            # letter = removePadding(letter)\n",
    "            try:\n",
    "                cv2.imwrite(f\"{os.getcwd()}/temp/letters0/{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "            except:\n",
    "                print(\"#:\", line_count, word_count, letter_count)\n",
    "\n",
    "\n",
    "width_sum, height_sum, count = 0, 0, 0\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            temp_letter = removePadding(letter)\n",
    "            # temp_letter = letter\n",
    "            width_sum += temp_letter.shape[1]\n",
    "            height_sum += temp_letter.shape[0]\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 18\n"
     ]
    }
   ],
   "source": [
    "AVG_HEIGHT = math.floor(height_sum / count)\n",
    "AVG_WIDTH = math.floor(width_sum / count)\n",
    "print(AVG_HEIGHT, AVG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterSegmentation(letter, avg_width_or_height, rotate = False):\n",
    "    letter = removePadding(letter)\n",
    "    AVG_WIDTH_OR_HEIGHT = avg_width_or_height\n",
    "    sub_let = [letter]\n",
    "    max_idx = 0     # index of the image with max width or height\n",
    "    \n",
    "    while (sub_let[max_idx].shape[1] if rotate else sub_let[max_idx].shape[0]) > AVG_WIDTH_OR_HEIGHT*1.5:\n",
    "        sub_let_img = sub_let[max_idx]\n",
    "        \n",
    "        gray = cv2.cvtColor(sub_let_img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        gray = np.rot90(gray, 3) if rotate else gray\n",
    "        _, binary_img = cv2.threshold(gray, np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # if rotate: _, binary_img = cv2.threshold(np.rot90(gray, 3), np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "        # # _, binary_img = cv2.threshold(np.rot90(gray, 3), 64, 255, cv2.THRESH_BINARY_INV)\n",
    "        # else: _, binary_img = cv2.threshold(gray, np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        pixel_values = []\n",
    "        sum_histogram = np.asarray([sum(row) for row in binary_img])\n",
    "        \n",
    "        if rotate:\n",
    "            idx_arr = sum_histogram[AVG_WIDTH_OR_HEIGHT//2: len(sum_histogram)-AVG_WIDTH_OR_HEIGHT//4]\n",
    "        else:\n",
    "            idx_arr = sum_histogram[AVG_WIDTH_OR_HEIGHT//4:len(sum_histogram)-AVG_WIDTH_OR_HEIGHT//4]\n",
    "        \n",
    "        if idx_arr.size == 0: break\n",
    "        \n",
    "        # idx = AVG_WIDTH_OR_HEIGHT // 2 + idx_arr.index(min(idx_arr))\n",
    "        if rotate: idx =  AVG_WIDTH_OR_HEIGHT//2 + np.where(idx_arr==np.min(idx_arr[np.nonzero(idx_arr)]))[0][0]\n",
    "        else: idx = AVG_WIDTH_OR_HEIGHT//4 + np.where(idx_arr==np.min(idx_arr[np.nonzero(idx_arr)]))[0][0]\n",
    "        \n",
    "        \n",
    "        left, right = sub_let[:max_idx], sub_let[max_idx+1:]\n",
    "        # pixel_values = [[0, idx+1], [idx-1, len(binary_img)]]\n",
    "        if rotate: pixel_values = [[0, idx], [idx, len(binary_img)]]\n",
    "        else: pixel_values = [[0, idx+1], [idx-1, len(binary_img)]]\n",
    "        \n",
    "        if rotate: cropped_sub_let = cropImage(pixel_values, sub_let_img, rotate=True)\n",
    "        else: cropped_sub_let = cropImage(pixel_values, sub_let_img)\n",
    "        \n",
    "        sub_let = [*left, *cropped_sub_let, *right]\n",
    "        \n",
    "        # max_idx = sub_let.index(max(sub_let, key=lambda x: x.shape[1]))\n",
    "        max_idx = 0\n",
    "        for i, img in enumerate(sub_let):\n",
    "            if rotate:\n",
    "                if img.shape[1] > sub_let[max_idx].shape[1]:\n",
    "                    max_idx = i\n",
    "            else:\n",
    "                if img.shape[0] > sub_let[max_idx].shape[0]:\n",
    "                    max_idx = i\n",
    "        # for i, img in enumerate(sub_let):\n",
    "        #     if img == []\n",
    "    return sub_let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_ARTICLE_LETTERS = []\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    temp_line = []\n",
    "    for word_count, word in enumerate(line):\n",
    "        temp_word = []\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            if letter.shape[1] > AVG_WIDTH*1.25:\n",
    "                # print(\"w\", line_count, word_count, letter_count)\n",
    "                sub_let_horizontal = letterSegmentation(letter, AVG_WIDTH, True)\n",
    "                temp_word = [*temp_word, *sub_let_horizontal]\n",
    "            else: temp_word.append(letter)\n",
    "        temp_line.append(temp_word)\n",
    "    TEMP_ARTICLE_LETTERS.append(temp_line)\n",
    "ARTICLE_LETTERS = TEMP_ARTICLE_LETTERS\n",
    "\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            try:\n",
    "                cv2.imwrite(f\"{os.getcwd()}/temp/letters1/{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "                # cv2.imwrite(f\"{os.getcwd()}/temp/letters1/{line_count}_{word_count}_{letter_count}.jpg\", imageContrast(cv2.resize(letter, (32, 32))))\n",
    "            except:\n",
    "                print(\"#:\", line_count, word_count, letter_count)\n",
    "\n",
    "TEMP_ARTICLE_LETTERS = []\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    temp_line = []\n",
    "    for word_count, word in enumerate(line):\n",
    "        temp_word = []\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            # if line_count == 6 and word_count == 1 and letter_count == 0: continue\n",
    "            # if line_count == 11 and word_count == 3 and letter_count == 0: continue\n",
    "            if letter.shape[0] > AVG_HEIGHT*1.25:\n",
    "                # print(\"h\", line_count, word_count, letter_count)\n",
    "                # sub_let_vertical = []\n",
    "                # print(len(sub_let_vertical), end=\"####\")\n",
    "                # process = multiprocessing.Process(target=letterSegmentation, args=[letter, AVG_HEIGHT, False, sub_let_vertical])\n",
    "                # process.start()\n",
    "                \n",
    "                # if process.is_alive():\n",
    "                #     process.kill()\n",
    "                #     cv2.imwrite(\n",
    "                #         f\"./not_working/{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "                #     process.join()\n",
    "                sub_let_vertical = letterSegmentation(letter, AVG_HEIGHT)\n",
    "                # print(len(sub_let_vertical))\n",
    "                temp_word = [*temp_word, *sub_let_vertical]\n",
    "            else:\n",
    "                temp_word.append(letter)\n",
    "        temp_line.append(temp_word)\n",
    "    TEMP_ARTICLE_LETTERS.append(temp_line)\n",
    "ARTICLE_LETTERS = TEMP_ARTICLE_LETTERS\n",
    "\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            try:\n",
    "                # cv2.imwrite(f\"{os.getcwd()}/temp/letters2/{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "                cv2.imwrite(f\"{os.getcwd()}/temp/letters2/{line_count}_{word_count}_{letter_count}.jpg\", imageContrast(cv2.resize(letter, (32, 32))))\n",
    "            except:\n",
    "                print(\"#:\", line_count, word_count, letter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
