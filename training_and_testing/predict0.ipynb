{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "import time\n",
    "import multiprocessing\n",
    "from functools import wraps\n",
    "# import diplib as dip\n",
    "# from skimage import img_as_ubyte\n",
    "# from utils.preprocess import resize\n",
    "# from skimage.filters import threshold_otsu\n",
    "# from utils.zhangSuenThinning import zhangSuen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPadding(image, all=None):\n",
    "    '''\n",
    "    - ``Input``: an image\n",
    "    - ``Output``:\n",
    "        - add padding top: 10, bottom: 20 - ((height + top) % 10), left: 10, right: 20 - ((width + left) % 10)\n",
    "        - so that the image can be divided into 10 equal parts vertically\n",
    "    '''\n",
    "    image = np.asarray(image)\n",
    "    height, width, channels = image.shape\n",
    "    # print(height, width, channels)\n",
    "    image = Image.fromarray(image)\n",
    "    if all == None:\n",
    "        top = 10\n",
    "        bottom = 20 - ((height+top) % 10)\n",
    "        left = 10\n",
    "        right = 20 - ((width+left) % 10)\n",
    "    else: top, right, bottom, left = all, all, all, all\n",
    "    new_width = width + left + right\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(image.mode, (new_width, new_height), (255, 255, 255))\n",
    "    result.paste(image, (left, top))\n",
    "    result = np.asarray(result)\n",
    "    # cv2.imshow('result', result)\n",
    "    # cv2.waitKey(0)\n",
    "    # print(result.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePadding(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, binary_image = cv2.threshold(\n",
    "        gray, 0, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY_INV\n",
    "    )\n",
    "    for i in range(4):\n",
    "        while sum(binary_image[0]) == 0:\n",
    "            image = image[1:]\n",
    "            binary_image = binary_image[1:]\n",
    "        image = np.rot90(image)\n",
    "        binary_image = np.rot90(binary_image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempDisplay(dict_):\n",
    "    \"\"\"\n",
    "    - `Input`: dictionary\n",
    "        - ``key``: name for the image to be displayed\n",
    "        - ``value``: image to be displayed\n",
    "    - `Output`: a matplotlib plot with the all the images in the dictionary in one image\n",
    "    \"\"\"\n",
    "    rows = int(math.sqrt(len(dict_)))\n",
    "    cols = math.ceil(len(dict_)/rows)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    i = 1\n",
    "    for key in dict_:\n",
    "        fig.add_subplot(rows, cols, i)\n",
    "        i = i + 1\n",
    "        plt.imshow(dict_[key])\n",
    "        plt.axis('off')\n",
    "        plt.title(str(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(pixel_values, original_image, rotate=False):\n",
    "    '''\n",
    "    - `Input`: \n",
    "        - ``pixel_values``: vertical pixel values range [from, to] to be cropped\n",
    "        - ``original_image``: image from which the cropped images are needed\n",
    "        - ``rotate``: if the image is to be rotated or not before the cropping (used for word segmentation form the line images)\n",
    "    - `Output`: cropped images from the ``original_image``\n",
    "    '''\n",
    "    image = original_image\n",
    "    if rotate:\n",
    "        image = np.rot90(image, 3)\n",
    "    cropped_images = []\n",
    "    h, w = image.shape[:2]\n",
    "    # dp = {}\n",
    "    for i in range(len(pixel_values)):\n",
    "        crop_image = image[pixel_values[i][0]:pixel_values[i][1], 0:w]\n",
    "        # dp[i] = crop_image\n",
    "        if rotate:\n",
    "            cropped_images.append(np.rot90(crop_image))\n",
    "        else:\n",
    "            cropped_images.append(crop_image)\n",
    "    # tempDisplay(dp)\n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# def imageContrast(image):\n",
    "#     image_contrast = np.zeros(image.shape, image.dtype)\n",
    "#     alpha = 1.1  # Simple contrast control and alpha value [1.0 - 3.0]\n",
    "#     beta = 5    # Simple brightness control and beta value [0 - 100]\n",
    "#     for y in range(image.shape[0]):\n",
    "#         for x in range(image.shape[1]):\n",
    "#             for c in range(image.shape[2]):\n",
    "#                 image_contrast[y, x, c] = np.clip(alpha * image[y, x, c] + beta, 0, 255)\n",
    "#     return image_contrast\n",
    "def imageContrast(image, alpha=1.1, beta=5):\n",
    "    # Convert the input image to a float32 array for better precision\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Apply the contrast and brightness adjustments using NumPy functions\n",
    "    image_contrast = np.clip(alpha * image + beta, 0, 255).astype(np.uint8)\n",
    "\n",
    "    image = Image.fromarray(image_contrast)\n",
    "\n",
    "    new_image = image\n",
    "\n",
    "    filter = ImageEnhance.Contrast(new_image)\n",
    "    new_image = filter.enhance(1.25)\n",
    "\n",
    "    filter = ImageEnhance.Sharpness(new_image)\n",
    "    new_image = filter.enhance(1.25)\n",
    "    \n",
    "    new_image = np.asarray(new_image)\n",
    "    \n",
    "    # cv2.imwrite(\"contrast.jpg\", new_image)\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(image, line_segmentation=False, word_segmentation=False, letter_segmentation=False):\n",
    "    \"\"\"\n",
    "    - `Input`:\n",
    "        - ``image``: image to be segmented\n",
    "        - ``rotate``: ``bool`` if the image is to be rotated or not (used for word segmentation form the line images)\n",
    "    - `Output`: vertical pixel values range [from, to] to be cropped \n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    ret, image = cv2.threshold(\n",
    "        image, 128, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # ret, image = cv2.threshold(image, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # ret, image = cv2.threshold(image, np.mean(image), 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # rect_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 4))\n",
    "    rect_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 2))\n",
    "    \n",
    "    \n",
    "    if line_segmentation:\n",
    "        line_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 1))\n",
    "        image = cv2.erode(image, rect_kernel_2, iterations=1)\n",
    "        image = cv2.dilate(image, line_kernel, iterations=1)\n",
    "        # cv2.imwrite(\"temp.jpg\", image)\n",
    "        \n",
    "    if word_segmentation:\n",
    "        image = np.rot90(image, 3)    \n",
    "        # para_image = cv2.dilate(image, rect_kernel_2, iterations=6)\n",
    "        image = cv2.dilate(image, rect_kernel_2, iterations=4)\n",
    "        # cv2.imshow(\"image\", image)\n",
    "        # cv2.waitKey(0)\n",
    "        # image = word_image\n",
    "    \n",
    "    if letter_segmentation:\n",
    "        image = np.rot90(image, 3)\n",
    "        # cv2.imshow(\"image\", image)\n",
    "        # cv2.waitKey(0)\n",
    "        # letter_kernel_10 = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "        # letter_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "        # image = cv2.erode(image, letter_kernel_10, iterations=2)\n",
    "        # image = cv2.dilate(image, letter_kernel_2, iterations=2)\n",
    "        # image = cv2.dilate(image, rect_kernel_2, iterations=1)\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    pixel_values = []\n",
    "    temp = []\n",
    "    for i in range(1, h):\n",
    "        if len(temp) == 2:\n",
    "            pixel_values.append(temp)\n",
    "            temp = []\n",
    "        \n",
    "        if len(temp) == 0 and sum(image[i-1]) == 0 and sum(image[i]) != 0:\n",
    "            temp.append(i - 1)\n",
    "        \n",
    "        if len(temp) == 1 and sum(image[i-1]) != 0 and sum(image[i]) == 0:\n",
    "            temp.append(i + 1)\n",
    "\n",
    "    return pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D\\Documents\\0Final_Year_Project\\line_word_char_segmentation\\img\\0_5.jpg\n"
     ]
    }
   ],
   "source": [
    "# 83\n",
    "img_name = \"0_0.jpg\"\n",
    "img_name = \"0_1.jpg\"\n",
    "img_name = \"0_3.jpg\"\n",
    "img_name = \"0_4.jpg\"\n",
    "img_name = \"0_5.jpg\"\n",
    "IMAGE_PATH = f\"{os.getcwd()}\\\\img\\\\{img_name}\"\n",
    "print(IMAGE_PATH)\n",
    "ORIGINAL_IMAGE = cv2.imread(IMAGE_PATH)\n",
    "ORIGINAL_IMAGE = addPadding(ORIGINAL_IMAGE)\n",
    "ORIGINAL_IMAGE = imageContrast(ORIGINAL_IMAGE)\n",
    "\n",
    "\n",
    "\n",
    "# image = ORIGINAL_IMAGE\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "# _, binary_img = cv2.threshold(image, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "# _, binary_img = cv2.threshold(binary_img, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "# ORIGINAL_IMAGE = resize(ORIGINAL_IMAGE, 250)\n",
    "\n",
    "####\n",
    "# the following function can also be used for line segmentation\n",
    "# and a similar function can be used for word segmentation\n",
    "# def line_dilation(image):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     ret, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "#     rect_kernel_110 = cv2.getStructuringElement(cv2.MORPH_RECT, (500, 1))\n",
    "#     dilation = cv2.dilate(thresh, rect_kernel_110, iterations=1)\n",
    "#     return dilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = f\"{os.getcwd()}\\\\temp\"\n",
    "folder_names = [\"lines\", \"words\", \"thin_words\", \"letters0\", \"letters1\", \"letters2\"]\n",
    "\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    if not os.path.exists(f\"{temp_path}\\\\{folder_name}\"):\n",
    "        os.mkdir(f\"{temp_path}\\\\{folder_name}\")\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    folder_path = f\"{temp_path}\\\\{folder_name}\"\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = f\"{folder_path}\\\\{file}\"\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = segmentation(ORIGINAL_IMAGE, line_segmentation=True)\n",
    "ARTICLE_LINES = cropImage(pixel_values, ORIGINAL_IMAGE)\n",
    "\n",
    "for i, line in enumerate(ARTICLE_LINES):\n",
    "    # tempDisplay({i: ARTICLE_LINES[i]})\n",
    "    cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\lines\\\\{i}.jpg\", line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_WORDS = []\n",
    "for line in ARTICLE_LINES:\n",
    "    pixel_values = segmentation(line, word_segmentation=True)\n",
    "    words = cropImage(pixel_values, line, rotate=True)\n",
    "    # words = [resize(word, 2000) for word in words]\n",
    "    ARTICLE_WORDS.append(words)\n",
    "    # tempDisplay({i: words[i] for i in range(len(words))})\n",
    "\n",
    "\n",
    "# mh, mw = 0, 0\n",
    "# for line in ARTICLE_WORDS:\n",
    "#     for i, word in enumerate(line):\n",
    "#         mh, mw = max(mh, word.shape[0]), max(mw, word.shape[1])\n",
    "# print(mh, mw)\n",
    "\n",
    "line_count = 0\n",
    "for line in ARTICLE_WORDS:\n",
    "    # tempDisplay({i: word for i, word in enumerate(line)})\n",
    "    for word_count, word in enumerate(line):\n",
    "        cv2.imwrite(\n",
    "            f\"{os.getcwd()}\\\\temp\\\\words\\\\{line_count}_{word_count}.jpg\", word)\n",
    "    line_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARTICLE_LETTERS = []\n",
    "# for line in ARTICLE_WORDS:\n",
    "#     temp_line = []\n",
    "#     for word in line:\n",
    "#         pixel_values = segmentation(word, letter_segmentation=True)\n",
    "#         letters = cropImage(pixel_values, word, True)\n",
    "#         # tempDisplay({i : letters[i] for i in range(len(letters))})\n",
    "#         temp_line.append(letters)\n",
    "#     ARTICLE_LETTERS.append(temp_line)\n",
    "\n",
    "\n",
    "# for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "#     for word_count, word in enumerate(line):\n",
    "#         # tempDisplay({i: letter for i, letter in enumerate(word)})\n",
    "#         for letter_count, letter in enumerate(word):\n",
    "#             cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\letters\\\\{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = 1\n",
    "\n",
    "def word2Letters(image):\n",
    "    # image = resize(image, 500)\n",
    "    org_img = image.copy()\n",
    "    img_copy = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    ret, binary_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # _, binary_img = cv2.threshold(gray, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "    # _, binary_img = cv2.threshold(gray, np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # dist = cv2.distanceTransform(binary_img, cv2.DIST_C, 3)\n",
    "    # ret, sure_fg = cv2.threshold(dist, 0.15 * dist.max(), 255, cv2.THRESH_BINARY)\n",
    "    # sure_fg = sure_fg.astype(np.uint8)\n",
    "    # binary_img = sure_fg\n",
    "    \n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    # binary_img = cv2.erode(sure_fg, kernel, iterations=1)\n",
    "    \n",
    "    thinned_img = binary_img\n",
    "    # thinned_img = cv2.ximgproc.thinning(binary_img,  thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    # thinned_img = cv2.dilate(thinned_img, kernel, iterations=1)\n",
    "    \n",
    "    # thinned_img = zhangSuen(binary_img).astype(np.uint8)\n",
    "    # thinned_img*=255\n",
    "    \n",
    "    # binary_img = np.array(binary_img, dtype=np.uint8)\n",
    "    # binary_img = binary_img > 128\n",
    "    # thinned_img = dip.EuclideanSkeleton(binary_img, endPixelCondition='three neighbors')\n",
    "    # thinned_img = np.array(thinned_img, dtype=np.uint8)\n",
    "    # thinned_img *= 255\n",
    "    \n",
    "    \n",
    "    # global cc\n",
    "    # cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\thin_words\\\\{cc}.jpg\", thinned_img)\n",
    "    # cc += 1\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        thinned_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "    cropped_images = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # rect = cv2.rectangle(img_copy, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "        x1, y1, x2, y2 = x - 2, y - 2, x + w + 2, y + h + 2\n",
    "        # x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "        cropped = org_img[y1 : y2, x1 : x2]\n",
    "        cropped_images.append(cropped)\n",
    "    return cropped_images\n",
    "    \n",
    "    \n",
    "    # _, img = cv2.threshold(thinned_img, 75, 255, cv2.THRESH_BINARY_INV)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    # pixel_values = segmentation(img, letter_segmentation=True)\n",
    "    # return pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_LETTERS = []\n",
    "for line in ARTICLE_WORDS:\n",
    "    temp_line = []\n",
    "    for word in line:\n",
    "        word = addPadding(word, 2)\n",
    "        # pixel_values = word2Letters(word)\n",
    "        # letters = cropImage(pixel_values, word, True)\n",
    "        letters = word2Letters(word)\n",
    "        temp_line.append(letters)\n",
    "        # temp_line.append([removePadding(letter) for letter in letters])\n",
    "    ARTICLE_LETTERS.append(temp_line)\n",
    "\n",
    "\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            # letter = removePadding(letter)\n",
    "            try:\n",
    "                cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\letters0\\\\{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "            except:\n",
    "                print(\"#:\", line_count, word_count, letter_count)\n",
    "\n",
    "\n",
    "width_sum, height_sum, count = 0, 0, 0\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            temp_letter = removePadding(letter)\n",
    "            # temp_letter = letter\n",
    "            width_sum += temp_letter.shape[1]\n",
    "            height_sum += temp_letter.shape[0]\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "AVG_HEIGHT = math.floor(height_sum / count)\n",
    "AVG_WIDTH = math.floor(width_sum / count)\n",
    "print(AVG_HEIGHT, AVG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterSegmentation(letter, avg_width_or_height, rotate = False):\n",
    "    letter = removePadding(letter)\n",
    "    AVG_WIDTH_OR_HEIGHT = avg_width_or_height\n",
    "    sub_let = [letter]\n",
    "    max_idx = 0     # index of the image with max width or height\n",
    "    \n",
    "    while (sub_let[max_idx].shape[1] if rotate else sub_let[max_idx].shape[0]) > AVG_WIDTH_OR_HEIGHT*1.5:\n",
    "        sub_let_img = sub_let[max_idx]\n",
    "        \n",
    "        gray = cv2.cvtColor(sub_let_img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        gray = np.rot90(gray, 3) if rotate else gray\n",
    "        _, binary_img = cv2.threshold(gray, np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # if rotate: _, binary_img = cv2.threshold(np.rot90(gray, 3), np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "        # # _, binary_img = cv2.threshold(np.rot90(gray, 3), 64, 255, cv2.THRESH_BINARY_INV)\n",
    "        # else: _, binary_img = cv2.threshold(gray, np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        pixel_values = []\n",
    "        sum_histogram = np.asarray([sum(row) for row in binary_img])\n",
    "        \n",
    "        if rotate:\n",
    "            idx_arr = sum_histogram[AVG_WIDTH_OR_HEIGHT//2: len(sum_histogram)-AVG_WIDTH_OR_HEIGHT//4]\n",
    "        else:\n",
    "            idx_arr = sum_histogram[AVG_WIDTH_OR_HEIGHT//4:len(sum_histogram)-AVG_WIDTH_OR_HEIGHT//4]\n",
    "        \n",
    "        if idx_arr.size == 0: break\n",
    "        \n",
    "        # idx = AVG_WIDTH_OR_HEIGHT // 2 + idx_arr.index(min(idx_arr))\n",
    "        if rotate: idx =  AVG_WIDTH_OR_HEIGHT//2 + np.where(idx_arr==np.min(idx_arr[np.nonzero(idx_arr)]))[0][0]\n",
    "        else: idx = AVG_WIDTH_OR_HEIGHT//4 + np.where(idx_arr==np.min(idx_arr[np.nonzero(idx_arr)]))[0][0]\n",
    "        \n",
    "        \n",
    "        left, right = sub_let[:max_idx], sub_let[max_idx+1:]\n",
    "        # pixel_values = [[0, idx+1], [idx-1, len(binary_img)]]\n",
    "        if rotate: pixel_values = [[0, idx], [idx, len(binary_img)]]\n",
    "        else: pixel_values = [[0, idx+1], [idx-1, len(binary_img)]]\n",
    "        \n",
    "        if rotate: cropped_sub_let = cropImage(pixel_values, sub_let_img, rotate=True)\n",
    "        else: cropped_sub_let = cropImage(pixel_values, sub_let_img)\n",
    "        \n",
    "        sub_let = [*left, *cropped_sub_let, *right]\n",
    "        \n",
    "        # max_idx = sub_let.index(max(sub_let, key=lambda x: x.shape[1]))\n",
    "        max_idx = 0\n",
    "        for i, img in enumerate(sub_let):\n",
    "            if rotate:\n",
    "                if img.shape[1] > sub_let[max_idx].shape[1]:\n",
    "                    max_idx = i\n",
    "            else:\n",
    "                if img.shape[0] > sub_let[max_idx].shape[0]:\n",
    "                    max_idx = i\n",
    "        # for i, img in enumerate(sub_let):\n",
    "        #     if img == []\n",
    "    return sub_let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_ARTICLE_LETTERS = []\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    temp_line = []\n",
    "    for word_count, word in enumerate(line):\n",
    "        temp_word = []\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            if letter.shape[1] > AVG_WIDTH*1.25:\n",
    "                # print(\"w\", line_count, word_count, letter_count)\n",
    "                sub_let_horizontal = letterSegmentation(letter, AVG_WIDTH, True)\n",
    "                temp_word = [*temp_word, *sub_let_horizontal]\n",
    "            else: temp_word.append(letter)\n",
    "        temp_line.append(temp_word)\n",
    "    TEMP_ARTICLE_LETTERS.append(temp_line)\n",
    "ARTICLE_LETTERS = TEMP_ARTICLE_LETTERS\n",
    "\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            try:\n",
    "                cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\letters1\\\\{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "                # cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\letters1\\\\{line_count}_{word_count}_{letter_count}.jpg\", imageContrast(cv2.resize(letter, (32, 32))))\n",
    "            except:\n",
    "                print(\"#:\", line_count, word_count, letter_count)\n",
    "\n",
    "TEMP_ARTICLE_LETTERS = []\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    temp_line = []\n",
    "    for word_count, word in enumerate(line):\n",
    "        temp_word = []\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            # if line_count == 6 and word_count == 1 and letter_count == 0: continue\n",
    "            # if line_count == 11 and word_count == 3 and letter_count == 0: continue\n",
    "            if letter.shape[0] > AVG_HEIGHT*1.25:\n",
    "                # print(\"h\", line_count, word_count, letter_count)\n",
    "                # sub_let_vertical = []\n",
    "                # print(len(sub_let_vertical), end=\"####\")\n",
    "                # process = multiprocessing.Process(target=letterSegmentation, args=[letter, AVG_HEIGHT, False, sub_let_vertical])\n",
    "                # process.start()\n",
    "                \n",
    "                # if process.is_alive():\n",
    "                #     process.kill()\n",
    "                #     cv2.imwrite(\n",
    "                #         f\"./not_working/{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "                #     process.join()\n",
    "                sub_let_vertical = letterSegmentation(letter, AVG_HEIGHT)\n",
    "                # print(len(sub_let_vertical))\n",
    "                temp_word = [*temp_word, *sub_let_vertical]\n",
    "            else:\n",
    "                temp_word.append(letter)\n",
    "        temp_line.append(temp_word)\n",
    "    TEMP_ARTICLE_LETTERS.append(temp_line)\n",
    "ARTICLE_LETTERS = TEMP_ARTICLE_LETTERS\n",
    "\n",
    "for line_count, line in enumerate(ARTICLE_LETTERS):\n",
    "    for word_count, word in enumerate(line):\n",
    "        for letter_count, letter in enumerate(word):\n",
    "            try:\n",
    "                cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\letters2\\\\{line_count}_{word_count}_{letter_count}.jpg\", letter)\n",
    "                # cv2.imwrite(f\"{os.getcwd()}\\\\temp\\\\letters2\\\\{line_count}_{word_count}_{letter_count}.jpg\", imageContrast(cv2.resize(letter, (32, 32))))\n",
    "            except:\n",
    "                print(\"#:\", line_count, word_count, letter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 348ms/step\n",
      "0_0_0 ꯲ ꯲\n",
      "Most active neuron: 2 (98.31%)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "0_0_1 ꯵ ꯨ\n",
      "Most active neuron: 50 (66.60%)\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "0_1_0 ꯗ ꯹\n",
      "Most active neuron: 9 (97.93%)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "0_1_1 ꯥ ꯵\n",
      "Most active neuron: 5 (59.38%)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "0_2_0 ꯈ ꯈ\n",
      "Most active neuron: 18 (88.70%)\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "0_2_1 ꯨ ꯎ\n",
      "Most active neuron: 24 (100.00%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "0_2_10 ꯌ ꯝ\n",
      "Most active neuron: 39 (100.00%)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "0_2_2 ꯨ ꯎ\n",
      "Most active neuron: 24 (79.71%)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "0_2_3 ꯃ ꯆ\n",
      "Most active neuron: 16 (100.00%)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "0_2_4 ꯌ ꯎ\n",
      "Most active neuron: 24 (99.86%)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "0_2_5 ꯨ ꯎ\n",
      "Most active neuron: 24 (96.22%)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "0_2_6 ꯝ ꯃ\n",
      "Most active neuron: 13 (61.54%)\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "0_2_7 ꯗ ꯆ\n",
      "Most active neuron: 16 (100.00%)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "0_2_8 ꯠ ꯎ\n",
      "Most active neuron: 24 (100.00%)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "0_2_9 ꯇ ꯎ\n",
      "Most active neuron: 24 (95.63%)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "0_3_0 ( ꯇ\n",
      "Most active neuron: 17 (78.96%)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "0_3_1 ꯔ ꯕ\n",
      "Most active neuron: 31 (97.75%)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "0_3_2 ꯤ ꯇ\n",
      "Most active neuron: 17 (99.99%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "0_4_0 ꯆ ꯪ\n",
      "Most active neuron: 52 (99.76%)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "0_4_1 ꯤ ꯬\n",
      "Most active neuron: 54 (98.78%)\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "0_4_2 ) ꯚ\n",
      "Most active neuron: 36 (69.15%)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "0_4_3 ꯀ ꯪ\n",
      "Most active neuron: 52 (59.64%)\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "0_4_4 ꯭ ꯜ\n",
      "Most active neuron: 38 (100.00%)\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "0_4_5 ꯋ ꯆ\n",
      "Most active neuron: 16 (100.00%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "0_4_6 ꯥ ꯡ\n",
      "Most active neuron: 43 (60.30%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "0_4_7 ꯀ ꯜ\n",
      "Most active neuron: 38 (92.63%)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0_4_8 ꯩ ꯩ\n",
      "Most active neuron: 51 (54.85%)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0_4_9 ꯊ ꯧ\n",
      "Most active neuron: 49 (75.63%)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1_0_0 ꯦ ꯸\n",
      "Most active neuron: 8 (30.98%)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1_1_0 ꯜ ꯨ\n",
      "Most active neuron: 50 (77.92%)\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1_2_0 ꯀ ꯨ\n",
      "Most active neuron: 50 (96.97%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2_0_0 ꯣ ꯀ\n",
      "Most active neuron: 10 (87.54%)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "2_0_1 ꯡ ꯆ\n",
      "Most active neuron: 16 (100.00%)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "2_0_2 ꯖ ꯨ\n",
      "Most active neuron: 50 (98.31%)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "2_0_3 ꯦ ꯒ\n",
      "Most active neuron: 28 (93.12%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2_0_4 ꯡ ꯧ\n",
      "Most active neuron: 49 (83.23%)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "2_0_5 ꯂ ꯘ\n",
      "Most active neuron: 34 (87.95%)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "2_0_6 ꯩ ꯦ\n",
      "Most active neuron: 48 (99.78%)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "2_0_7 ꯀ ꯜ\n",
      "Most active neuron: 38 (100.00%)\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "2_1_0 ꯥ ꯀ\n",
      "Most active neuron: 10 (99.99%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2_1_1 ꯏ ꯹\n",
      "Most active neuron: 9 (70.59%)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "2_1_2 ꯗ ꯛ\n",
      "Most active neuron: 37 (53.65%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2_1_3 ꯇ ꯁ\n",
      "Most active neuron: 11 (92.09%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2_1_4 ꯥ ꯦ\n",
      "Most active neuron: 48 (99.99%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2_1_5 ꯏ ꯒ\n",
      "Most active neuron: 28 (93.57%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2_2_0 ꯕ ꯈ\n",
      "Most active neuron: 18 (92.07%)\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "2_2_1 ꯪ ꯧ\n",
      "Most active neuron: 49 (72.01%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2_2_2 ꯃ ꯀ\n",
      "Most active neuron: 10 (100.00%)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "2_2_3 ꯤ ꯆ\n",
      "Most active neuron: 16 (42.95%)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "2_2_4 ꯀ ꯋ\n",
      "Most active neuron: 21 (72.54%)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2_2_5 ꯞ ꯬\n",
      "Most active neuron: 54 (79.14%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2_2_6 ꯊ ꯍ\n",
      "Most active neuron: 23 (50.55%)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "2_3_0 ꯣ ꯇ\n",
      "Most active neuron: 17 (99.75%)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "2_3_1 ꯛ ꯨ\n",
      "Most active neuron: 50 (96.97%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2_3_2 ꯈ ꯍ\n",
      "Most active neuron: 23 (95.26%)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "2_3_3 ꯤ ꯩ\n",
      "Most active neuron: 51 (90.90%)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "2_3_4 ꯫ ꯪ\n",
      "Most active neuron: 52 (74.46%)\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "3_0_0 ꯄ ꯝ\n",
      "Most active neuron: 39 (94.29%)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "3_0_1 ꯂ ꯞ\n",
      "Most active neuron: 40 (85.73%)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "3_0_2 ꯦ ꯞ\n",
      "Most active neuron: 40 (94.79%)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "3_0_3 ꯝ ꯀ\n",
      "Most active neuron: 10 (99.99%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "3_0_4 - ꯞ\n",
      "Most active neuron: 40 (99.61%)\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "3_1_0 ꯄ ꯃ\n",
      "Most active neuron: 13 (62.33%)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "3_1_1 ꯅ ꯹\n",
      "Most active neuron: 9 (71.50%)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "3_1_2 ꯊ ꯛ\n",
      "Most active neuron: 37 (97.88%)\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "3_1_3 ꯧ ꯈ\n",
      "Most active neuron: 18 (78.42%)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "3_1_4 ꯒ ꯕ\n",
      "Most active neuron: 31 (97.77%)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "3_1_5 ꯤ ꯞ\n",
      "Most active neuron: 40 (70.60%)\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "3_2_0 ꯃ ꯎ\n",
      "Most active neuron: 24 (99.93%)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "3_2_1 ꯤ ꯫\n",
      "Most active neuron: 53 (82.75%)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "3_3_0 ꯡ ꯤ\n",
      "Most active neuron: 46 (42.61%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "3_3_1 ꯂ ꯞ\n",
      "Most active neuron: 40 (99.99%)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "3_3_2 ꯦ ꯅ\n",
      "Most active neuron: 15 (71.56%)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "3_3_3 ꯟ ꯦ\n",
      "Most active neuron: 48 (99.99%)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "3_3_4 ꯅ ꯝ\n",
      "Most active neuron: 39 (100.00%)\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "3_4_0 ꯒ ꯎ\n",
      "Most active neuron: 24 (70.41%)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "3_5_0 ꯤ ꯭\n",
      "Most active neuron: 55 (63.76%)\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "3_5_1 ꯇ ꯞ\n",
      "Most active neuron: 40 (99.92%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "3_5_2 ꯥ ꯩ\n",
      "Most active neuron: 51 (98.08%)\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "3_5_3 ꯑ ꯆ\n",
      "Most active neuron: 16 (83.70%)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "3_5_4 ꯃ ꯀ\n",
      "Most active neuron: 10 (85.27%)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "3_5_5 ꯁ ꯘ\n",
      "Most active neuron: 34 (99.99%)\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "3_5_6 ꯨ ꯉ\n",
      "Most active neuron: 19 (65.83%)\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\D\\Documents\\0Final_Year_Project\\line_word_char_segmentation\\predict0.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/0Final_Year_Project/line_word_char_segmentation/predict0.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m output_neuron \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions[\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/0Final_Year_Project/line_word_char_segmentation/predict0.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m temp\u001b[39m.\u001b[39mappend(output_neuron)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/0Final_Year_Project/line_word_char_segmentation/predict0.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mimg_file_path\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00morg_text[i]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mgoogle[output_neuron]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/0Final_Year_Project/line_word_char_segmentation/predict0.ipynb#X23sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMost active neuron: \u001b[39m\u001b[39m{\u001b[39;00moutput_neuron\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m predictions[\u001b[39m0\u001b[39m][output_neuron]\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(f'{os.getcwd()}/weights/character_model_vgg16.h5')\n",
    "images_path = f\"{os.getcwd()}/temp/letters2\"\n",
    "org_text = \"꯲꯵ꯗꯥꯈꯨꯌꯨꯃꯌꯨꯝꯗꯠꯇ(ꯔꯤꯆꯤ)ꯀ꯭ꯋꯥꯀꯩꯊꯦꯜꯀꯣꯡꯖꯦꯡꯂꯩꯀꯥꯏꯗꯇꯥꯏꯕꯪꯃꯤꯀꯞꯊꯣꯛꯈꯤ꯫ꯄꯂꯦꯝ-ꯄꯅꯊꯧꯒꯤꯃꯤꯡꯂꯦꯟꯅꯒꯤꯇꯥꯑꯃꯁꯨ\"\n",
    "json_object = json.load(open(\"./meetei_mayek.json\", \"r\"))\n",
    "google = json_object[\"google\"]\n",
    "\n",
    "# temp = []\n",
    "# data = np.empty((len(os.listdir(images_path)), 32, 32, 3))\n",
    "# for i, img_file_path in enumerate(os.listdir(images_path)):\n",
    "#     img = cv2.imread(f\"{images_path}\\\\{img_file_path}\")\n",
    "#     if img.shape[0] == 0 or img.shape[1] == 0: continue\n",
    "#     data[i] = np.asarray(cv2.resize(img, (32, 32)))\n",
    "# predictions = model.predict(data)\n",
    "# for i in range(len(data)):\n",
    "#     output_neuron = np.argmax(predictions[i])\n",
    "#     temp.append(output_neuron)\n",
    "#     print('Most active neuron: {} ({:.2f}%)'.format(output_neuron, 100 * predictions[i][output_neuron]))\n",
    "\n",
    "# ꯲꯵ꯗꯥꯈꯨꯌꯨꯃꯌꯨꯝꯗꯠꯇ(ꯔꯤꯆꯤ)ꯀ꯭ꯋꯥꯀꯩꯊꯦꯜꯀꯣꯡꯖꯦꯡꯂꯩꯀꯥꯏꯗꯇꯥꯏꯕꯪꯃꯤꯀꯞꯊꯣꯛꯈꯤ꯫ꯄꯂꯦꯝ-ꯄꯅꯊꯧꯒꯤꯃꯤꯡꯂꯦꯟꯅꯒꯤꯇꯥꯑꯃꯁꯨ\n",
    "\n",
    "temp = []\n",
    "for i, img_file_path in enumerate(os.listdir(images_path)):\n",
    "    data = np.empty((1, 32, 32, 3))\n",
    "    img = cv2.imread(f\"{images_path}\\\\{img_file_path}\")\n",
    "    if img.shape[0] == 0 or img.shape[1] == 0:\n",
    "        continue\n",
    "    data[0] = np.asarray(cv2.resize(img, (32, 32)))\n",
    "    predictions = model.predict(data)\n",
    "    # for i in range(len(data)):\n",
    "    output_neuron = np.argmax(predictions[0])\n",
    "    temp.append(output_neuron)\n",
    "    print(f\"{img_file_path.split('.')[0]} {org_text[i]} {google[output_neuron]}\")\n",
    "    print(f\"Most active neuron: {output_neuron} ({100 * predictions[0][output_neuron]:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['꯲', 'ꯨ', '꯹', '꯵', 'ꯈ', 'ꯎ', 'ꯝ', 'ꯎ', 'ꯆ', 'ꯎ', 'ꯎ', 'ꯃ', 'ꯆ', 'ꯎ', 'ꯎ', 'ꯇ', 'ꯕ', 'ꯇ', 'ꯪ', '꯬', 'ꯚ', 'ꯪ', 'ꯜ', 'ꯆ', 'ꯡ', 'ꯜ', 'ꯩ', 'ꯧ', '꯸', 'ꯨ', 'ꯨ', 'ꯀ', 'ꯆ', 'ꯨ', 'ꯒ', 'ꯧ', 'ꯘ', 'ꯦ', 'ꯜ', 'ꯀ', '꯹', 'ꯛ', 'ꯁ', 'ꯦ', 'ꯒ', 'ꯈ', 'ꯧ', 'ꯀ', 'ꯆ', 'ꯋ', '꯬', 'ꯍ', 'ꯇ', 'ꯨ', 'ꯍ', 'ꯩ', 'ꯪ', 'ꯝ', 'ꯞ', 'ꯞ', 'ꯀ', 'ꯞ', 'ꯃ', '꯹', 'ꯛ', 'ꯈ', 'ꯕ', 'ꯞ', 'ꯎ', '꯫', 'ꯤ', 'ꯞ', 'ꯅ', 'ꯦ', 'ꯝ', 'ꯎ', '꯭', 'ꯞ', 'ꯩ', 'ꯆ', 'ꯀ', 'ꯘ', 'ꯉ', 'ꯪ', 'ꯝ', 'ꯝ', 'ꯪ', 'ꯝ', 'ꯇ', 'ꯣ', 'ꯞ', 'ꯛ', 'ꯇ', 'ꯦ', 'ꯟ', 'ꯅ', 'ꯒ', 'ꯪ', 'ꯞ', 'ꯝ', 'ꯁ', 'ꯨ']\n",
      "66\n",
      "0.40746031746031747\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jellyfish\n",
    "\n",
    "org_text = \"꯲꯵ꯗꯥꯈꯨꯌꯨꯃꯌꯨꯝꯗꯠꯇ(ꯔꯤꯆꯤ)ꯀ꯭ꯋꯥꯀꯩꯊꯦꯜꯀꯣꯡꯖꯦꯡꯂꯩꯀꯥꯏꯗꯇꯥꯏꯕꯪꯃꯤꯀꯞꯊꯣꯛꯈꯤ꯫ꯄꯂꯦꯝ-ꯄꯅꯊꯧꯒꯤꯃꯤꯡꯂꯦꯟꯅꯒꯤꯇꯥꯑꯃꯁꯨ\"\n",
    "json_object = json.load(open(\"./meetei_mayek.json\", \"r\"))\n",
    "google = json_object[\"google\"]\n",
    "text = \"\"\n",
    "for i in temp: text+=google[i]\n",
    "print(list(text))\n",
    "print(jellyfish.damerau_levenshtein_distance(org_text, text))\n",
    "print(jellyfish.jaro_distance(org_text, text))\n",
    "print(jellyfish.levenshtein_distance(org_text, text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
