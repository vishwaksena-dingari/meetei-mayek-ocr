{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stacked generalization with neural net meta model on blobs dataset\n",
    "# from sklearn.datasets import make_blobs\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from keras.models import load_model\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.utils import plot_model\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import concatenate\n",
    "# from numpy import argmax\n",
    "# from numpy import dstack\n",
    "# import os\n",
    "# from keras.utils import to_categorical\n",
    "# from skimage.transform import resize\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from keras.models import load_model, Model, Sequential\n",
    "# from keras.layers import Concatenate, Dense\n",
    "# from keras.optimizers import Adam\n",
    "# stacked generalization with linear meta model on blobs dataset\n",
    "# from sklearn.datasets import make_blobs\n",
    "# from keras.utils import to_categorical\n",
    "# from numpy import dstack\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from keras.applications import vgg16\n",
    "# from keras.applications import xception\n",
    "from keras.applications import mobilenet_v2, vgg16, vgg19, resnet_v2, xception\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 models\n"
     ]
    }
   ],
   "source": [
    "# load models from file\n",
    "def load_all_models(models_dir):\n",
    "    # model_paths = ['model1.h5', 'model2.h5', 'model3.h5']\n",
    "    models_path = [model for model in os.listdir(models_dir)]\n",
    "    models = []\n",
    "    for path in models_path:\n",
    "        model_path = f\"{models_dir}\\\\{path}\"\n",
    "        model = load_model(model_path)\n",
    "        model.trainable = False\n",
    "        models.append(model)\n",
    "\n",
    "    # for model in models:\n",
    "    #     model.summary()\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        for layer in model.layers:\n",
    "            layer._name = f\"ensemble_{i}_{layer.name}\"\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# load all models\n",
    "members = load_all_models(f\"{os.getcwd()}\\\\models\\\\\")\n",
    "print(\"Loaded %d models\" % len(members))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D\\Documents\\00Final_Year_Project\\training_and_testing\n",
      "22400\n",
      "20160\n",
      "2240\n",
      "0 "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (13,8,3) into shape (96,96,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\D\\Documents\\00Final_Year_Project\\training_and_testing\\ensemble.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/00Final_Year_Project/training_and_testing/ensemble.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# image = cv2.resize(image, (32, 32))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/00Final_Year_Project/training_and_testing/ensemble.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mif\u001b[39;00m j \u001b[39m<\u001b[39m size \u001b[39m-\u001b[39m test_size:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/00Final_Year_Project/training_and_testing/ensemble.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     data[count] \u001b[39m=\u001b[39m image\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/00Final_Year_Project/training_and_testing/ensemble.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     labels[count] \u001b[39m=\u001b[39m i\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/D/Documents/00Final_Year_Project/training_and_testing/ensemble.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (13,8,3) into shape (96,96,3)"
     ]
    }
   ],
   "source": [
    "# Loading the data and generating labels\n",
    "IMG_SIZE = 96\n",
    "image_height, image_width = IMG_SIZE, IMG_SIZE\n",
    "no_of_color_channels = 3\n",
    "root_dir = os.getcwd()\n",
    "db_dir = f\"{root_dir}/ensemble_db\"\n",
    "no_of_classes = len(os.listdir(db_dir))\n",
    "print(root_dir)\n",
    "\n",
    "total_no_of_images = len(\n",
    "    list(glob.glob(f\"{db_dir}/[0-9]*/*.*\", recursive=True)))\n",
    "print(total_no_of_images)\n",
    "\n",
    "count = 0\n",
    "# test_size = 2 # from each class\n",
    "test_size = int((total_no_of_images / 56) * 10 / 100)  # from each class\n",
    "train_size = total_no_of_images - no_of_classes * test_size\n",
    "data = np.empty((train_size, image_height, image_width, no_of_color_channels))\n",
    "labels = np.empty(train_size, dtype=int)\n",
    "\n",
    "test_count = 0\n",
    "test_data = np.empty(\n",
    "    (no_of_classes * test_size, image_height, image_width, no_of_color_channels)\n",
    ")\n",
    "test_labels = np.empty(no_of_classes * test_size, dtype=int)\n",
    "\n",
    "print(train_size)\n",
    "print(no_of_classes * test_size)\n",
    "\n",
    "for i in range(no_of_classes):\n",
    "    class_dir = root_dir + \"/\" + \"mmdb_400\" + \"/\" + str(i)\n",
    "    class_images = glob.glob(class_dir + \"/*.*\")\n",
    "    np.random.shuffle(class_images)\n",
    "    size = len(class_images)\n",
    "    print(i, end=\" \") if i == 0 or i % 10 != 0 else print(i)\n",
    "    for j in range(size):\n",
    "        image_path = class_images[j]\n",
    "        image = cv2.imread(image_path)\n",
    "        # image = cv2.resize(image, (32, 32))\n",
    "        if j < size - test_size:\n",
    "            data[count] = image\n",
    "            labels[count] = i\n",
    "            count += 1\n",
    "        else:\n",
    "            test_data[test_count] = image\n",
    "            test_labels[test_count] = i\n",
    "            test_count += 1\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_96, train_labels = shuffle(data, labels)\n",
    "train_data_71 = []\n",
    "train_data_32 = []\n",
    "\n",
    "test_data_96 = test_data\n",
    "test_data_71 = []\n",
    "test_data_32 = []\n",
    "\n",
    "for image in train_data_96:\n",
    "    train_data_71.append(cv2.resize(image, (71, 71)))\n",
    "    train_data_32.append(cv2.resize(image, (32, 32)))\n",
    "train_data_96 = np.asarray(train_data_96)\n",
    "train_data_71 = np.asarray(train_data_71)\n",
    "train_data_32 = np.asarray(train_data_32)\n",
    "\n",
    "for image in test_data_96:\n",
    "    test_data_71.append(cv2.resize(image, (71, 71)))\n",
    "    test_data_32.append(cv2.resize(image, (32, 32)))\n",
    "test_data_96 = np.asarray(test_data_96)\n",
    "test_data_71 = np.asarray(test_data_71)\n",
    "test_data_32 = np.asarray(test_data_32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    \"vgg16\": vgg16.preprocess_input(train_data_32),\n",
    "    \"vgg19\": vgg19.preprocess_input(train_data_32),\n",
    "    \"resnet\": resnet_v2.preprocess_input(train_data_32),\n",
    "    \"xception\": xception.preprocess_input(train_data_71),\n",
    "    \"mobilenet\": mobilenet_v2.preprocess_input(train_data_96),\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"vgg16\": vgg16.preprocess_input(test_data_32),\n",
    "    \"vgg19\": vgg19.preprocess_input(test_data_32),\n",
    "    \"resnet\": resnet_v2.preprocess_input(test_data_32),\n",
    "    \"xception\": xception.preprocess_input(test_data_71),\n",
    "    \"mobilenet\": mobilenet_v2.preprocess_input(test_data_96),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n",
      "0.0 255.0\n",
      "-123.68 151.061\n",
      "-123.68 151.061\n",
      "-1.0 1.0\n",
      "-1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# # Preprocess training and testing data\n",
    "\n",
    "# print(data.min(), data.max())\n",
    "# print(test_data.min(), test_data.max())\n",
    "\n",
    "# # for i in range(len(data)):\n",
    "# #   data[i] = preprocess_input(data[i])\n",
    "# # for i in range(len(test_data)):\n",
    "# #   test_data[i] = preprocess_input(test_data[i])\n",
    "\n",
    "# data = vgg16.preprocess_input(data)\n",
    "# test_data = vgg16.preprocess_input(test_data)\n",
    "\n",
    "# data_2 = xception.preprocess_input(data_2)\n",
    "# test_data_2 = xception.preprocess_input(test_data_2)\n",
    "\n",
    "# print(data.min(), data.max())\n",
    "# print(test_data.min(), test_data.max())\n",
    "# print(data_2.min(), data_2.max())\n",
    "# print(test_data_2.min(), test_data_2.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_data(model_name, data):\n",
    "    if \"vgg16\" in model_name:\n",
    "        x = data[\"vgg16\"]\n",
    "    elif \"vgg19\" in model_name:\n",
    "        x = data[\"vgg19\"]\n",
    "    elif \"resnet\" in model_name:\n",
    "        x = data[\"resnet\"]\n",
    "    elif \"mobilenet\" in model_name:\n",
    "        x = data[\"mobilenet\"]\n",
    "    elif \"xception\" in model_name:\n",
    "        x = data[\"xception\"]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.984\n",
      "Model Accuracy: 0.983\n",
      "Model Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "# evaluate standalone models on test dataset\n",
    "for i, model in enumerate(members):\n",
    "\t# testy_enc = to_categorical(test_labels)\n",
    "\ttest_y = test_labels\n",
    "\tmodel_name = model.layers[0].name\n",
    "\ttest_x = get_appropriate_data(model_name, test_data)\n",
    "\t_, acc = model.evaluate(test_x, test_y, verbose='auto')\n",
    "\tprint('Model Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def stacked_dataset(members, inputX):\n",
    "    stackX = None\n",
    "    for i, model in enumerate(members):\n",
    "        # make prediction\n",
    "        # yhat = model.predict(inputX[1] if i == 2 else inputX[0], verbose=0)\n",
    "        inputX = get_appropriate_data(model.layers[0].name, inputX)\n",
    "        yhat = model.predict(inputX)\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        else:\n",
    "            stackX = np.dstack((stackX, yhat))\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape(\n",
    "        (stackX.shape[0], stackX.shape[1] * stackX.shape[2]))\n",
    "    return stackX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit a model based on the outputs from the ensemble members\n",
    "# def fit_stacked_model(members, inputX, inputy):\n",
    "# \t# create dataset using ensemble\n",
    "# \tprint(\"e\")\n",
    "# \tstackedX = stacked_dataset(members, inputX)\n",
    "# \t# fit standalone model\n",
    "# \tmodel = LogisticRegression()\n",
    "# \t# Callbacks: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# \t# es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "# \tearlystop = EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "# \t\t\t\t\t\t\tpatience=10, verbose=1, restore_best_weights=True)\n",
    "# \tcheckpoint = ModelCheckpoint(\n",
    "# \t\t'mobilenetv2_mmdb_400.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "# \t# rlronp = ReduceLROnPlateau( monitor=\"val_accuracy\", factor=0.005,patience=1, verbose=1)\n",
    "# \trlronp = ReduceLROnPlateau(\n",
    "# \t\tmonitor='val_loss', factor=0.5, patience=5, verbose=1,  min_lr=0.00001)\n",
    "\n",
    "# \tcallbacks = [earlystop, checkpoint, rlronp]\n",
    "# \tprint(\"fitting...\")\n",
    "# \tmodel.fit(stackedX, inputy, epochs=200,\n",
    "#            shuffle=True,\n",
    "#            verbose='auto',\n",
    "#            callbacks=callbacks,\n",
    "#            validation_split=0.1)\n",
    "# \t# model.fit(stackedX, inputy)\n",
    "# \treturn model\n",
    "\n",
    "\n",
    "# # make a prediction with the stacked model\n",
    "# def stacked_prediction(members, model, inputX):\n",
    "# \t# create dataset using ensemble\n",
    "# \tstackedX = stacked_dataset(members, inputX)\n",
    "# \t# make a prediction\n",
    "# \tyhat = model.predict(stackedX)\n",
    "# \treturn yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit stacked model using the ensemble\n",
    "# model = fit_stacked_model(members, train_data, train_labels)\n",
    "# # evaluate model on test set\n",
    "# yhat = stacked_prediction(members, model, test_data)\n",
    "# acc = accuracy_score(test_labels, yhat)\n",
    "# print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 120s 190ms/step\n",
      "632/632 [==============================] - 162s 256ms/step\n",
      "632/632 [==============================] - 363s 571ms/step\n",
      "69/69 [==============================] - 15s 217ms/step\n",
      "69/69 [==============================] - 21s 288ms/step\n",
      "69/69 [==============================] - 39s 559ms/step\n"
     ]
    }
   ],
   "source": [
    "stackedX = stacked_dataset(members, train_data)\n",
    "test_stackedX = stacked_dataset(members, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model based on the outputs from the ensemble members\n",
    "def fit_stacked_model(stackedX, inputy):\n",
    "    # fit standalone model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "\n",
    "\n",
    "# make a prediction with the stacked model\n",
    "def stacked_prediction(model, test_stackedX):\n",
    "    # make a prediction\n",
    "    yhat = model.predict(test_stackedX)\n",
    "    return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Test Accuracy: 0.995\n"
     ]
    }
   ],
   "source": [
    "# fit stacked model using the ensemble\n",
    "model = fit_stacked_model(stackedX, train_labels)\n",
    "# evaluate model on test set\n",
    "yhat = stacked_prediction(model, test_stackedX)\n",
    "acc = accuracy_score(test_labels, yhat)\n",
    "print(\"Stacked Test Accuracy: %.3f\" % acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
