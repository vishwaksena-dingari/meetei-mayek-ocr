{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LYJIVyUy_Dl",
        "outputId": "cdf819cd-ea69-48fd-d86a-e78be0d81e0f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "na0A1pOGVRne"
      },
      "outputs": [],
      "source": [
        "!rm -rf sample_data\n",
        "!rm -rf mmdb_400\n",
        "!rm -rf mmdb_400_96\n",
        "!rm -rf mmdb_400_96_bw\n",
        "# !rm -rf segmented\n",
        "# !rm -rf segmented_224\n",
        "# !rm -rf random.png random_data.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnHeiT3xVTSJ",
        "outputId": "47247265-fdb8-44d3-f999-b2552461f21b"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/combined_segmented.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/png.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/bw_segmented.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/tempdb.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400_96.zip'\n",
        "!unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400_96.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PqstXKx3CiW0"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# root_dir = os.listdir()\n",
        "# # os.rename('combined_segmented', 'segmented')\n",
        "# # os.rename('png', 'segmented')\n",
        "# # os.rename('bw_segmented', 'segmented')\n",
        "# os.rename('tempdb', 'segmented')\n",
        "# # os.rename('testdb', 'segmented')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8kKUzzT6CSmG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# from imageio import imread\n",
        "# from keras.utils import to_categorical\n",
        "# from skimage.transform import resize\n",
        "import glob\n",
        "import math\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.applications.resnet_v2 import preprocess_input\n",
        "from keras.applications.resnet_v2 import ResNet152V2\n",
        "from keras import Model\n",
        "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from keras import layers, models\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import EarlyStopping,  ModelCheckpoint, ReduceLROnPlateau\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPTQXUDfpFpm",
        "outputId": "cf2319e1-c800-417c-822d-69ddaa459bf5"
      },
      "outputs": [],
      "source": [
        "# Loading the data and generating labels\n",
        "\n",
        "IMG_SIZE = 96\n",
        "image_height, image_width = IMG_SIZE, IMG_SIZE\n",
        "no_of_color_channels = 3\n",
        "root_dir = os.getcwd()\n",
        "db_dir = f\"{root_dir}/mmdb_400_96\"\n",
        "no_of_classes = len(os.listdir(db_dir))\n",
        "print(root_dir)\n",
        "\n",
        "total_no_of_images = len(list(glob.glob(f\"{db_dir}/[0-9]*/*.*\", recursive=True)))\n",
        "print(total_no_of_images)\n",
        "\n",
        "count = 0\n",
        "# test_size = 2 # from each class\n",
        "test_size = int((total_no_of_images/56)*10/100)  # from each class\n",
        "train_size = total_no_of_images - no_of_classes * test_size\n",
        "data = np.empty((train_size, image_height, image_width, no_of_color_channels))\n",
        "labels = np.empty(train_size, dtype=int)\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "test_count = 0\n",
        "test_data = np.empty((no_of_classes*test_size, image_height, image_width, no_of_color_channels))\n",
        "test_labels = np.empty(no_of_classes*test_size, dtype=int)\n",
        "# test_data = []\n",
        "# test_labels = []\n",
        "\n",
        "print(train_size)\n",
        "print(no_of_classes*test_size)\n",
        "\n",
        "for i in range(no_of_classes):\n",
        "    class_dir = f\"{db_dir}/{i}\"\n",
        "    class_images = glob.glob(class_dir+'/*.*')\n",
        "    np.random.shuffle(class_images)\n",
        "    \n",
        "    # class_images = [cv2.resize(cv2.imread(image_path), (32, 32)) for image_path in class_images]\n",
        "    # test_data = [*test_data, *class_images[:test_size]]\n",
        "    # test_labels = [*test_labels, *[i]*len(class_images[:test_size])]\n",
        "    # data = [*data, *class_images[test_size:]]\n",
        "    # labels = [*labels, *[i]*len(class_images[test_size:])]\n",
        "    \n",
        "    size = len(class_images)\n",
        "    print(i, end=\" \") if i == 0 or i % 10 != 0 else print(i)\n",
        "    for j in range(size):\n",
        "        image_path = class_images[j]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "        if j < size-test_size:\n",
        "          data[count] = image\n",
        "          labels[count] = i\n",
        "          count += 1\n",
        "        else:\n",
        "          test_data[test_count] = image\n",
        "          test_labels[test_count] = i\n",
        "          test_count += 1\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUJW4k5gpFpn",
        "outputId": "1c92f410-f76f-4e65-a260-5e9dd43cc301"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "test_data = np.array(test_data)\n",
        "labels = np.array(labels)\n",
        "test_labels = np.array(test_labels)\n",
        "print(data.shape, test_data.shape)\n",
        "print(labels.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1qJ95gyfpFpn"
      },
      "outputs": [],
      "source": [
        "def tempDisplay(dict_):\n",
        "    \"\"\"\n",
        "    - `Input`: dictionary\n",
        "        - ``key``: name for the image to be displayed\n",
        "        - ``value``: image to be displayed\n",
        "    - `Output`: a matplotlib plot with the all the images in the dictionary in one image\n",
        "    \"\"\"\n",
        "    rows = int(math.sqrt(len(dict_)))\n",
        "    cols = math.ceil(len(dict_)/rows)\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    i = 1\n",
        "    for key in dict_:\n",
        "        fig.add_subplot(rows, cols, i)\n",
        "        i = i + 1\n",
        "        plt.imshow(dict_[key])\n",
        "        plt.axis('off')\n",
        "        plt.title(str(key))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "F2DbqOQw33Mn"
      },
      "outputs": [],
      "source": [
        "# Shuffle Data\n",
        "\n",
        "data, labels = shuffle(data, labels)\n",
        "# test_data, test_labels = shuffle(test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "U2Ttg1MsLCj6",
        "outputId": "349b2163-dbdd-4458-8c81-736cafe3c403"
      },
      "outputs": [],
      "source": [
        "r = random.randrange(train_size)\n",
        "cv2.imwrite(root_dir+'/random_image.png', data[r])\n",
        "# plt.imshow(data[r])\n",
        "tempDisplay({\"data[r]\": np.asarray(data[r])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HwXHU1X44qI",
        "outputId": "61714faa-2942-41ca-eb33-4e4220913665"
      },
      "outputs": [],
      "source": [
        "# Preprocess training and testing data\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())\n",
        "\n",
        "# for i in range(len(data)):\n",
        "#   data[i] = preprocess_input(data[i])\n",
        "# for i in range(len(test_data)):\n",
        "#   test_data[i] = preprocess_input(test_data[i])\n",
        "\n",
        "data = preprocess_input(data)\n",
        "test_data = preprocess_input(test_data)\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "YNsOxODrNt_A",
        "outputId": "8e2774f2-17dc-4b57-89bd-297706a36c42"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data[r])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VGC7rdzkWKUT"
      },
      "outputs": [],
      "source": [
        "# np.save(root_dir+'/data.npy', data)\n",
        "# np.save(root_dir+'/labels.npy', labels)\n",
        "# np.save(root_dir+'/test_data.npy', test_data)\n",
        "# np.save(root_dir+'/test_labels.npy', test_labels)\n",
        "# # data = np.load(root_dir+'/data.npy')\n",
        "# # labels = np.load(root_dir+'/labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "PXuKlkJIWOCB",
        "outputId": "7fb793b7-c223-4a46-e7f0-2758bbefdca8"
      },
      "outputs": [],
      "source": [
        " print(data[random.randrange(total_no_of_images)].shape)\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())\n",
        "print(labels)\n",
        "print(len(test_data), test_data[random.randrange(no_of_classes)].shape)\n",
        "# print(test_labels)\n",
        "\n",
        "img = np.array(cv2.imread(root_dir+'/random_image.png'))\n",
        "x = preprocess_input(img)\n",
        "cv2.imwrite(root_dir+'/p_random_image.png', x)\n",
        "p_img = np.array(cv2.imread(root_dir+'/p_random_image.png'))\n",
        "print(img.min(), img.max())\n",
        "print(p_img.min(), p_img.max())\n",
        "\n",
        "tempDisplay({\"img\": img, \"p_img\": p_img})\n",
        "\n",
        "# fig = plt.figure(figsize=(5, 5))\n",
        "# fig.add_subplot(1, 2, 1)\n",
        "# plt.imshow(img)\n",
        "# plt.axis('off')\n",
        "# fig.add_subplot(1, 2, 2)\n",
        "# plt.imshow(p_img)\n",
        "# plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuc0R4WqYsG5",
        "outputId": "278710af-b83b-4939-f848-f3d31954a7c5"
      },
      "outputs": [],
      "source": [
        "# Importing Resnet152V2\n",
        "\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "base_model = ResNet152V2(\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEH9fheYWQS1",
        "outputId": "adb1fcc3-88ab-491c-a455-8c6938ee83a1"
      },
      "outputs": [],
      "source": [
        "# Modifying the model\n",
        "\n",
        "avgpooling_layer_1 = GlobalAveragePooling2D()\n",
        "dense_layer_1 = Dense(1024, activation='relu')\n",
        "dense_layer_2 = Dense(1024, activation='relu')\n",
        "dense_layer_3 = Dense(512, activation='relu')\n",
        "prediction_layer = Dense(no_of_classes, activation='softmax')\n",
        "\n",
        "character_model = models.Sequential([\n",
        "    base_model,\n",
        "    avgpooling_layer_1,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    dense_layer_3,\n",
        "    prediction_layer,\n",
        "])\n",
        "character_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "AHn2B-OzWSoN"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "\n",
        "# learning_rate = 0.0001\n",
        "# epochs=200\n",
        "# decay_rate = learning_rate / epochs\n",
        "# momentum = 0.8\n",
        "# custom_sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate)\n",
        "\n",
        "# custom_adam = Adam(learning_rate=0.0000025)\n",
        "custom_adam = Adam(learning_rate=0.00025)\n",
        "\n",
        "character_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    # optimizer='adam',\n",
        "    optimizer=custom_adam,\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UaYjbLEsvPbK"
      },
      "outputs": [],
      "source": [
        "# Callbacks: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('resnet_152v2_mmdb_400.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "# rlronp = ReduceLROnPlateau( monitor=\"val_accuracy\", factor=0.005,patience=1, verbose=1)\n",
        "rlronp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1,  min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, checkpoint, rlronp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8AAEvyuWUbb",
        "outputId": "b2929fcd-2bcc-4ea8-ab95-85084026e05f"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = character_model.fit(\n",
        "    x=data,\n",
        "    y=labels,\n",
        "    epochs=200,\n",
        "    shuffle=True,\n",
        "    verbose='auto',\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "WAurau9upIvU",
        "outputId": "d8bc597f-3121-4131-aa43-5c847a6b5de0"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(37) #change accordingly of epochs that run \n",
        "plt.plot(epochs, loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "5QvgxcL41nKt",
        "outputId": "16e60ffe-e7e8-4f87-a33a-6a71dd366b3d"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "loss_train = history.history['accuracy']\n",
        "loss_val = history.history['val_accuracy']\n",
        "epochs = range(37) #change accordingly of epochs that run  \n",
        "plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "A49OXQuF6WWO"
      },
      "outputs": [],
      "source": [
        "character_model.save('resnet_152v2_mmdb_400.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R3ATWLbpFpu",
        "outputId": "e50143d1-00ed-4db7-9bc5-3617ea2ce074"
      },
      "outputs": [],
      "source": [
        "score = character_model.evaluate(test_data, test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW11h2nk5sfE",
        "outputId": "45bd6294-7a7e-439c-e7b0-4b6fa24acfd7"
      },
      "outputs": [],
      "source": [
        "predictions = character_model.predict(test_data)\n",
        "print('Shape: {}'.format(predictions.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r5SDmStB4isx",
        "outputId": "5930fe1a-96aa-4e82-cfda-9764fa8c3f4f"
      },
      "outputs": [],
      "source": [
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_test,y_scores, classNames):\n",
        "    # y_test=np.argmax(y_test, axis=1)\n",
        "    # y_scores=np.argmax(y_scores, axis=1)\n",
        "    classes = len(classNames)\n",
        "    cm = confusion_matrix(y_test, y_scores)\n",
        "    # print(\"**** Confusion Matrix ****\")\n",
        "    # print(cm)\n",
        "    # print(\"**** Classification Report ****\")\n",
        "    # print(classification_report(y_test, y_scores, target_names=classNames))\n",
        "    con = np.zeros((classes,classes))\n",
        "    for x in range(classes):\n",
        "        for y in range(classes):\n",
        "            con[x,y] = cm[x,y]/np.sum(cm[x,:])\n",
        "\n",
        "    plt.figure(figsize=(100,100))\n",
        "    sns.set(font_scale=2.0) # for label size\n",
        "    df = sns.heatmap(con, annot=True,fmt='.2', cmap='Blues',xticklabels= classNames , yticklabels= classNames)\n",
        "    df.figure.savefig(\"image2.png\")\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('F1 score: %f' % f1)\n",
        "# confusion matrix\n",
        "plot_confusion_matrix(test_labels, predicted_classes, [str(i) for i in range(56)])\n",
        " \n",
        "# # kappa\n",
        "# kappa = cohen_kappa_score(test_labels, predicted_classes)\n",
        "# print('Cohens kappa: %f' % kappa)\n",
        "# # ROC AUC\n",
        "# auc = roc_auc_score(test_labels, predicted_classes, multi_class=\"ovr\")\n",
        "# print('ROC AUC: %f' % auc)\n",
        "# matrix = multilabel_confusion_matrix(test_labels, predicted_classes)\n",
        "# # for i in range(len(matrix)):\n",
        "# #   for j in range(len(matrix[0])):\n",
        "# #     print(matrix[i][j], end=\" \")\n",
        "# #   print(\"\")\n",
        "# print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjpRLwLf4loq",
        "outputId": "6847b113-67ca-43ea-9043-f87f9bf66998"
      },
      "outputs": [],
      "source": [
        "print(classification_report(test_labels, predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT6jf6d_5vRq",
        "outputId": "e42754e8-bb3e-4459-b641-73079b1f07de"
      },
      "outputs": [],
      "source": [
        "for i in range(no_of_classes*test_size):\n",
        "  output_neuron = np.argmax(predictions[i])\n",
        "  print('Most active neuron: {} ({:.2f}%)'.format(\n",
        "      output_neuron,\n",
        "      100 * predictions[i][output_neuron]\n",
        "  ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "724EEP_5t3HZ",
        "outputId": "645b8427-dc37-4f5e-f19b-adceb48bc352"
      },
      "outputs": [],
      "source": [
        "top1_correct = 0\n",
        "top1_incorrect = 0\n",
        "top5_correct = 0\n",
        "top5_incorrect = 0\n",
        "for i in range(no_of_classes*test_size):\n",
        "  s = set()\n",
        "  sorted_predictions = np.sort(predictions[i])[::-1]\n",
        "  for j in range(5):\n",
        "    x = list(np.where(predictions[i]==sorted_predictions[j]))[0][0]\n",
        "    s.add(x)\n",
        "  # print(list(s))\n",
        "  if test_labels[i] in s: top5_correct+=1\n",
        "  else: top5_incorrect+=1\n",
        "  if test_labels[i] == np.argmax(predictions[i]): top1_correct+=1\n",
        "  else: top1_incorrect+=1\n",
        "\n",
        "print('Top-1 Accuracy: ', (top1_correct*100)/(top1_correct+top1_incorrect))\n",
        "print('Top-5 Accuracy: ', (top5_correct*100)/(top5_correct+top5_incorrect))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jHjucCYxVMAP"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMWaogRa7wPo"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4oFw9rcwSqB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoLm7qiVwS2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRW48WGawTAD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJDWCynA9_Jt"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
