{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjl1Rlj6-GIF",
        "outputId": "9561aed5-c9b5-4229-881a-66ced70277aa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HZB_Ez7C-GIN"
      },
      "outputs": [],
      "source": [
        "!rm -rf sample_data\n",
        "!rm -rf mmdb_400\n",
        "!rm -rf mmdb_400_96\n",
        "# !rm -rf segmented\n",
        "# !rm -rf segmented_224\n",
        "# !rm -rf random.png random_data.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRljyp-1-GIP",
        "outputId": "b9b4765f-92bf-435f-9ce6-7e5c18016745"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/combined_segmented.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/png.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/bw_segmented.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/tempdb.zip'\n",
        "!unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400_96.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "94txtKgY-GIT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# root_dir = os.listdir()\n",
        "# # os.rename('combined_segmented', 'segmented')\n",
        "# # os.rename('png', 'segmented')\n",
        "# # os.rename('bw_segmented', 'segmented')\n",
        "# os.rename('tempdb', 'segmented')\n",
        "# # os.rename('testdb', 'segmented')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RwUFLPHIOOOg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# from imageio import imread\n",
        "# from keras.utils import to_categorical\n",
        "# from skimage.transform import resize\n",
        "import glob\n",
        "import math\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.xception import preprocess_input\n",
        "from keras.applications.xception import Xception\n",
        "from keras import Model\n",
        "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from keras import models\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlq1pR6m-GSR",
        "outputId": "57d05c75-b037-4bd9-d879-ca60cd4a2140"
      },
      "outputs": [],
      "source": [
        "# Loading the data and generating labels\n",
        "\n",
        "IMG_SIZE = 71\n",
        "image_height, image_width = IMG_SIZE, IMG_SIZE\n",
        "no_of_color_channels = 3\n",
        "root_dir = os.getcwd()\n",
        "db_dir = f\"{root_dir}/mmdb_400_96\"\n",
        "no_of_classes = len(os.listdir(db_dir))\n",
        "print(root_dir)\n",
        "\n",
        "total_no_of_images = len(list(glob.glob(f\"{db_dir}/[0-9]*/*.*\", recursive=True)))\n",
        "print(total_no_of_images)\n",
        "\n",
        "count = 0\n",
        "# test_size = 2 # from each class\n",
        "test_size = int((total_no_of_images/56)*10/100)  # from each class\n",
        "train_size = total_no_of_images - no_of_classes * test_size\n",
        "data = np.empty((train_size, image_height, image_width, no_of_color_channels))\n",
        "labels = np.empty(train_size, dtype=int)\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "test_count = 0\n",
        "test_data = np.empty((no_of_classes*test_size, image_height, image_width, no_of_color_channels))\n",
        "test_labels = np.empty(no_of_classes*test_size, dtype=int)\n",
        "# test_data = []\n",
        "# test_labels = []\n",
        "\n",
        "print(train_size)\n",
        "print(no_of_classes*test_size)\n",
        "\n",
        "for i in range(no_of_classes):\n",
        "    class_dir = f\"{db_dir}/{i}\"\n",
        "    class_images = glob.glob(class_dir+'/*.*')\n",
        "    np.random.shuffle(class_images)\n",
        "\n",
        "    # class_images = [cv2.resize(cv2.imread(image_path), (32, 32)) for image_path in class_images]\n",
        "    # test_data = [*test_data, *class_images[:test_size]]\n",
        "    # test_labels = [*test_labels, *[i]*len(class_images[:test_size])]\n",
        "    # data = [*data, *class_images[test_size:]]\n",
        "    # labels = [*labels, *[i]*len(class_images[test_size:])]\n",
        "\n",
        "    size = len(class_images)\n",
        "    print(i, end=\" \") if i == 0 or i % 10 != 0 else print(i)\n",
        "    for j in range(size):\n",
        "        image_path = class_images[j]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "        if j < size-test_size:\n",
        "          data[count] = image\n",
        "          labels[count] = i\n",
        "          count += 1\n",
        "        else:\n",
        "          test_data[test_count] = image\n",
        "          test_labels[test_count] = i\n",
        "          test_count += 1\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVRdyAbKOOOi",
        "outputId": "2756960b-6db6-4363-91cd-6d901125d7ca"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "test_data = np.array(test_data)\n",
        "labels = np.array(labels)\n",
        "test_labels = np.array(test_labels)\n",
        "print(data.shape, test_data.shape)\n",
        "print(labels.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "92KhK7azrcjC"
      },
      "outputs": [],
      "source": [
        "def tempDisplay(dict_):\n",
        "    \"\"\"\n",
        "    - `Input`: dictionary\n",
        "        - ``key``: name for the image to be displayed\n",
        "        - ``value``: image to be displayed\n",
        "    - `Output`: a matplotlib plot with the all the images in the dictionary in one image\n",
        "    \"\"\"\n",
        "    rows = int(math.sqrt(len(dict_)))\n",
        "    cols = math.ceil(len(dict_)/rows)\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    i = 1\n",
        "    for key in dict_:\n",
        "        fig.add_subplot(rows, cols, i)\n",
        "        i = i + 1\n",
        "        plt.imshow(dict_[key])\n",
        "        plt.axis('off')\n",
        "        plt.title(str(key))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JLu13mUi-GSX"
      },
      "outputs": [],
      "source": [
        "# Shuffle Data\n",
        "\n",
        "data, labels = shuffle(data, labels)\n",
        "# test_data, test_labels = shuffle(test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "S2lvP2xm-GSg",
        "outputId": "7e720e52-03cf-4c72-ef82-0e6bbe64c3cb"
      },
      "outputs": [],
      "source": [
        "r = random.randrange(train_size)\n",
        "cv2.imwrite(root_dir+'/random_image.png', data[r])\n",
        "# plt.imshow(data[r])\n",
        "tempDisplay({\"data[r]\": np.asarray(data[r])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5YA25wH-GSk",
        "outputId": "78719900-481c-422a-9a99-97f463ae07d9"
      },
      "outputs": [],
      "source": [
        "# Preprocess training and testing data\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())\n",
        "\n",
        "# for i in range(len(data)):\n",
        "#   data[i] = preprocess_input(data[i])\n",
        "# for i in range(len(test_data)):\n",
        "#   test_data[i] = preprocess_input(test_data[i])\n",
        "\n",
        "data = preprocess_input(data)\n",
        "test_data = preprocess_input(test_data)\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "LrGrWfqY-GSq",
        "outputId": "fb8cc601-39a8-4758-97b8-a8d564c5c04e"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data[r])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_04qy2t2-GSs"
      },
      "outputs": [],
      "source": [
        "# np.save(root_dir+'/data.npy', data)\n",
        "# np.save(root_dir+'/labels.npy', labels)\n",
        "# np.save(root_dir+'/test_data.npy', test_data)\n",
        "# np.save(root_dir+'/test_labels.npy', test_labels)\n",
        "# # data = np.load(root_dir+'/data.npy')\n",
        "# # labels = np.load(root_dir+'/labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "4tqLcfMA-GSy",
        "outputId": "279eef3b-6529-480d-9377-2333806f0e52"
      },
      "outputs": [],
      "source": [
        "print(data[random.randrange(train_size)].shape)\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())\n",
        "print(labels)\n",
        "print(len(test_data), test_data[random.randrange(no_of_classes)].shape)\n",
        "# print(test_labels)\n",
        "\n",
        "img = np.array(cv2.imread(root_dir+'/random_image.png'))\n",
        "x = preprocess_input(img)\n",
        "cv2.imwrite(root_dir+'/p_random_image.png', x)\n",
        "p_img = np.array(cv2.imread(root_dir+'/p_random_image.png'))\n",
        "print(img.min(), img.max())\n",
        "print(p_img.min(), p_img.max())\n",
        "\n",
        "tempDisplay({\"img\": img, \"p_img\": p_img})\n",
        "\n",
        "# fig = plt.figure(figsize=(5, 5))\n",
        "# fig.add_subplot(1, 2, 1)\n",
        "# plt.imshow(img)\n",
        "# plt.axis('off')\n",
        "# fig.add_subplot(1, 2, 2)\n",
        "# plt.imshow(p_img)\n",
        "# plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPN5HKFZ-GSz",
        "outputId": "52b5ac83-98c7-4965-bc3b-6ddfd76b27f2"
      },
      "outputs": [],
      "source": [
        "# Importing ResNet152V2\n",
        "\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "base_model = Xception(\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OQKHbh3-GS5",
        "outputId": "8ecb3e96-29c9-4a66-9b2e-1d2a2dc73484"
      },
      "outputs": [],
      "source": [
        "# # # Modifying the model\n",
        "\n",
        "# flatten_layer = Flatten()\n",
        "# dense_layer_1 = Dense(128, activation='relu')\n",
        "# prediction_layer = Dense(no_of_classes, activation='softmax')\n",
        "\n",
        "# character_model = models.Sequential([\n",
        "#     base_model,\n",
        "#     flatten_layer,\n",
        "#     dense_layer_1,\n",
        "#     prediction_layer\n",
        "# ])\n",
        "# character_model.summary()\n",
        "\n",
        "\n",
        "# # # Modifying the model\n",
        "\n",
        "# flatten_layer = Flatten()\n",
        "# dense_layer_1 = Dense(64, activation='relu')\n",
        "# prediction_layer = Dense(no_of_classes, activation='softmax')\n",
        "\n",
        "# character_model = models.Sequential([\n",
        "#     base_model,\n",
        "#     flatten_layer,\n",
        "#     dense_layer_1,\n",
        "#     prediction_layer\n",
        "# ])\n",
        "# character_model.summary()\n",
        "\n",
        "\n",
        "avgpooling_layer_1 = GlobalAveragePooling2D()\n",
        "dense_layer_1 = Dense(512, activation='relu')\n",
        "dense_layer_2 = Dense(512, activation='relu')\n",
        "dense_layer_3 = Dense(256, activation='relu')\n",
        "prediction_layer = Dense(no_of_classes, activation='softmax')\n",
        "\n",
        "character_model = models.Sequential([\n",
        "    base_model,\n",
        "    avgpooling_layer_1,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    dense_layer_3,\n",
        "    prediction_layer,\n",
        "])\n",
        "character_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zFILAco9-GS9"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "\n",
        "# learning_rate = 0.00001\n",
        "# epochs=200\n",
        "# decay_rate = learning_rate / epochs\n",
        "# momentum = 0.8\n",
        "# custom_sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate)\n",
        "\n",
        "# custom_adam = Adam(learning_rate=0.00001)\n",
        "# custom_adam = Adam(learning_rate=0.0005)\n",
        "# custom_adam = Adam(learning_rate=0.0001)\n",
        "\n",
        "character_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SWjc33t5-GTG"
      },
      "outputs": [],
      "source": [
        "# Callbacks: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('xception_mmdb_400.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "# rlronp = ReduceLROnPlateau( monitor=\"val_accuracy\", factor=0.005,patience=1, verbose=1)\n",
        "rlronp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1,  min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, checkpoint, rlronp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMeoDUh-GTI",
        "outputId": "b3596965-850c-473e-ca54-f6072b36f777"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = character_model.fit(\n",
        "    x=data,\n",
        "    y=labels,\n",
        "    epochs=200,\n",
        "    shuffle=True,\n",
        "    verbose='auto',\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Ox_WSXyu-GTJ",
        "outputId": "141d06ed-04bf-44cb-9371-c8bbfc2746f1"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(28)  # change accordingly of epochs that run\n",
        "plt.plot(epochs, loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "aI9gtoKP-GTK",
        "outputId": "0ca27f74-b905-4ceb-84b4-5563eb65b7cc"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "loss_train = history.history['accuracy']\n",
        "loss_val = history.history['val_accuracy']\n",
        "epochs = range(28)  # change accordingly of epochs that run\n",
        "plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ajzElNNo-GTL"
      },
      "outputs": [],
      "source": [
        "character_model.save('xception_mmdb_400.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlX7W0OLOOOn",
        "outputId": "f077f835-024c-43a7-c0ad-8c3f6943f860"
      },
      "outputs": [],
      "source": [
        "score = character_model.evaluate(test_data, test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f-K3R_p-GTM",
        "outputId": "57e2d84c-9cf9-46c7-c8db-0df4aae6e9b3"
      },
      "outputs": [],
      "source": [
        "predictions = character_model.predict(test_data)\n",
        "print('Shape: {}'.format(predictions.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kkxdshd1REDU",
        "outputId": "ef3bd1df-6089-4342-dde6-1666e3c4bf9e"
      },
      "outputs": [],
      "source": [
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_test,y_scores, classNames):\n",
        "    # y_test=np.argmax(y_test, axis=1)\n",
        "    # y_scores=np.argmax(y_scores, axis=1)\n",
        "    classes = len(classNames)\n",
        "    cm = confusion_matrix(y_test, y_scores)\n",
        "    # print(\"**** Confusion Matrix ****\")\n",
        "    # print(cm)\n",
        "    # print(\"**** Classification Report ****\")\n",
        "    # print(classification_report(y_test, y_scores, target_names=classNames))\n",
        "    con = np.zeros((classes,classes))\n",
        "    for x in range(classes):\n",
        "        for y in range(classes):\n",
        "            con[x,y] = cm[x,y]/np.sum(cm[x,:])\n",
        "\n",
        "    plt.figure(figsize=(100,100))\n",
        "    sns.set(font_scale=2.0) # for label size\n",
        "    df = sns.heatmap(con, annot=True,fmt='.2', cmap='Blues',xticklabels= classNames , yticklabels= classNames)\n",
        "    df.figure.savefig(\"image2.png\")\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('F1 score: %f' % f1)\n",
        "# confusion matrix\n",
        "plot_confusion_matrix(test_labels, predicted_classes, [str(i) for i in range(56)])\n",
        " \n",
        "# # kappa\n",
        "# kappa = cohen_kappa_score(test_labels, predicted_classes)\n",
        "# print('Cohens kappa: %f' % kappa)\n",
        "# # ROC AUC\n",
        "# auc = roc_auc_score(test_labels, predicted_classes, multi_class=\"ovr\")\n",
        "# print('ROC AUC: %f' % auc)\n",
        "# matrix = multilabel_confusion_matrix(test_labels, predicted_classes)\n",
        "# # for i in range(len(matrix)):\n",
        "# #   for j in range(len(matrix[0])):\n",
        "# #     print(matrix[i][j], end=\" \")\n",
        "# #   print(\"\")\n",
        "# print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25uGh-srRG18",
        "outputId": "d28b976b-d727-4b8b-b4e1-51493e7cba78"
      },
      "outputs": [],
      "source": [
        "print(classification_report(test_labels, predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFbtVJcq-GTO",
        "outputId": "3df75f9f-3837-461d-8a36-3bfee15a5f2b"
      },
      "outputs": [],
      "source": [
        "for i in range(no_of_classes*test_size):\n",
        "  output_neuron = np.argmax(predictions[i])\n",
        "  print('Most active neuron: {} ({:.2f}%)'.format(\n",
        "      output_neuron,\n",
        "      100 * predictions[i][output_neuron]\n",
        "  ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUXPzuv--GTV",
        "outputId": "57659ba7-1c0a-4ac8-c1a9-fa05684fa018"
      },
      "outputs": [],
      "source": [
        "top1_correct = 0\n",
        "top1_incorrect = 0\n",
        "top5_correct = 0\n",
        "top5_incorrect = 0\n",
        "for i in range(no_of_classes*test_size):\n",
        "  s = set()\n",
        "  sorted_predictions = np.sort(predictions[i])[::-1]\n",
        "  for j in range(5):\n",
        "    x = list(np.where(predictions[i]==sorted_predictions[j]))[0][0]\n",
        "    s.add(x)\n",
        "  # print(list(s))\n",
        "  if test_labels[i] in s: top5_correct+=1\n",
        "  else: top5_incorrect+=1\n",
        "  if test_labels[i] == np.argmax(predictions[i]): top1_correct+=1\n",
        "  else: top1_incorrect+=1\n",
        "\n",
        "print('Top-1 Accuracy: ', (top1_correct*100)/(top1_correct+top1_incorrect))\n",
        "print('Top-5 Accuracy: ', (top5_correct*100)/(top5_correct+top5_incorrect))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GUQ-GsPLl9lA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "7173c644f055d2a259e0a2c1bc40b18a8a24299549bc16b9f24368822b3a4f54"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
