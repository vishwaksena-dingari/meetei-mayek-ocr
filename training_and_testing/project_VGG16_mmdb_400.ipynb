{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LYJIVyUy_Dl",
        "outputId": "36d2f005-2dc9-403e-8d55-1b925d20527e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "na0A1pOGVRne"
      },
      "outputs": [],
      "source": [
        "!rm -rf sample_data\n",
        "!rm -rf mmdb_550_32\n",
        "!rm -rf mmdb_400_32\n",
        "!rm -rf mmdb_400_32_bw\n",
        "!rm -rf mmdb_400\n",
        "!rm -rf mmdb_400_96\n",
        "# !rm -rf segmented\n",
        "# !rm -rf segmented_224\n",
        "# !rm -rf random.png random_data.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnHeiT3xVTSJ",
        "outputId": "ce70faca-e876-4b55-b6da-24505e52115a"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/combined_segmented.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/png.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/bw_segmented.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/tempdb.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_550_32.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400_32_bw.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400_32.zip'\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400.zip'\n",
        "!unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/mmdb_400_96.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PqstXKx3CiW0"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# root_dir = os.listdir()\n",
        "# # os.rename('combined_segmented', 'segmented')\n",
        "# # os.rename('png', 'segmented')\n",
        "# # os.rename('bw_segmented', 'segmented')\n",
        "# os.rename('tempdb', 'segmented')\n",
        "# # os.rename('testdb', 'segmented')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8kKUzzT6CSmG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# from imageio import imread\n",
        "# from keras.utils import to_categorical\n",
        "# from skimage.transform import resize\n",
        "import glob\n",
        "import math\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import Model\n",
        "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from keras import layers, models\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import EarlyStopping,  ModelCheckpoint, ReduceLROnPlateau\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hLJbm2aOmDM",
        "outputId": "9b3a2772-5482-4346-f3a3-b8740cedbe89"
      },
      "outputs": [],
      "source": [
        "# Loading the data and generating labels\n",
        "\n",
        "IMG_SIZE = 32\n",
        "image_height, image_width = IMG_SIZE, IMG_SIZE\n",
        "no_of_color_channels = 3\n",
        "root_dir = os.getcwd()\n",
        "db_dir = f\"{root_dir}/mmdb_400_96\"\n",
        "no_of_classes = len(os.listdir(db_dir))\n",
        "print(root_dir)\n",
        "\n",
        "total_no_of_images = len(list(glob.glob(f\"{db_dir}/[0-9]*/*.*\", recursive=True)))\n",
        "print(total_no_of_images)\n",
        "\n",
        "count = 0\n",
        "# test_size = 2 # from each class\n",
        "test_size = int((total_no_of_images/56)*10/100)  # from each class\n",
        "train_size = total_no_of_images - no_of_classes * test_size\n",
        "data = np.empty((train_size, image_height, image_width, no_of_color_channels))\n",
        "labels = np.empty(train_size, dtype=int)\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "test_count = 0\n",
        "test_data = np.empty((no_of_classes*test_size, image_height, image_width, no_of_color_channels))\n",
        "test_labels = np.empty(no_of_classes*test_size, dtype=int)\n",
        "# test_data = []\n",
        "# test_labels = []\n",
        "\n",
        "print(train_size)\n",
        "print(no_of_classes*test_size)\n",
        "\n",
        "for i in range(no_of_classes):\n",
        "    class_dir = f\"{db_dir}/{i}\"\n",
        "    class_images = glob.glob(class_dir+'/*.*')\n",
        "    class_images = shuffle(class_images)\n",
        "    \n",
        "    # class_images = [cv2.resize(cv2.imread(image_path), (32, 32)) for image_path in class_images]\n",
        "    # test_data = [*test_data, *class_images[:test_size]]\n",
        "    # test_labels = [*test_labels, *[i]*len(class_images[:test_size])]\n",
        "    # data = [*data, *class_images[test_size:]]\n",
        "    # labels = [*labels, *[i]*len(class_images[test_size:])]\n",
        "    \n",
        "    size = len(class_images)\n",
        "    print(i, end=\" \") if i == 0 or i % 10 != 0 else print(i)\n",
        "    for j in range(size):\n",
        "        image_path = class_images[j]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (32, 32))\n",
        "        if j < size-test_size:\n",
        "          data[count] = image\n",
        "          labels[count] = i\n",
        "          count += 1\n",
        "        else:\n",
        "          test_data[test_count] = image\n",
        "          test_labels[test_count] = i\n",
        "          test_count += 1\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dXUzDcWOmDN",
        "outputId": "fa12e17a-71f9-4869-abca-c69c39304828"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "test_data = np.array(test_data)\n",
        "labels = np.array(labels)\n",
        "test_labels = np.array(test_labels)\n",
        "print(data.shape, test_data.shape)\n",
        "print(labels.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ankud9MzOmDO"
      },
      "outputs": [],
      "source": [
        "def tempDisplay(dict_):\n",
        "    \"\"\"\n",
        "    - `Input`: dictionary\n",
        "        - ``key``: name for the image to be displayed\n",
        "        - ``value``: image to be displayed\n",
        "    - `Output`: a matplotlib plot with the all the images in the dictionary in one image\n",
        "    \"\"\"\n",
        "    rows = int(math.sqrt(len(dict_)))\n",
        "    cols = math.ceil(len(dict_)/rows)\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    i = 1\n",
        "    for key in dict_:\n",
        "        fig.add_subplot(rows, cols, i)\n",
        "        i = i + 1\n",
        "        plt.imshow(dict_[key])\n",
        "        plt.axis('off')\n",
        "        plt.title(str(key))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F2DbqOQw33Mn"
      },
      "outputs": [],
      "source": [
        "# Shuffle Data\n",
        "\n",
        "data, labels = shuffle(data, labels)\n",
        "# test_data, test_labels = shuffle(test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "U2Ttg1MsLCj6",
        "outputId": "d74fd4d2-6f49-4440-cdd2-30f156e2c0a4"
      },
      "outputs": [],
      "source": [
        "r = random.randrange(train_size)\n",
        "cv2.imwrite(root_dir+'/random_image.png', data[r])\n",
        "# plt.imshow(data[r])\n",
        "tempDisplay({\"data[r]\": data[r]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HwXHU1X44qI",
        "outputId": "a0b25788-4def-4db4-b672-bdf751f2989d"
      },
      "outputs": [],
      "source": [
        "# Preprocess training and testing data\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())\n",
        "\n",
        "# for i in range(len(data)):\n",
        "#   data[i] = preprocess_input(data[i])\n",
        "# for i in range(len(test_data)):\n",
        "#   test_data[i] = preprocess_input(test_data[i])\n",
        "\n",
        "data = preprocess_input(data)\n",
        "test_data = preprocess_input(test_data)\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "YNsOxODrNt_A",
        "outputId": "864ebfe1-100c-424d-b7ee-03b854f4154a"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data[r])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VGC7rdzkWKUT"
      },
      "outputs": [],
      "source": [
        "# np.save(root_dir+'/data.npy', data)\n",
        "# np.save(root_dir+'/labels.npy', labels)\n",
        "# np.save(root_dir+'/test_data.npy', test_data)\n",
        "# np.save(root_dir+'/test_labels.npy', test_labels)\n",
        "# # data = np.load(root_dir+'/data.npy')\n",
        "# # labels = np.load(root_dir+'/labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "PXuKlkJIWOCB",
        "outputId": "1221156f-dae1-42d7-bb01-187b4e0616ed"
      },
      "outputs": [],
      "source": [
        "print(data[random.randrange(train_size)].shape)\n",
        "\n",
        "print(data.min(), data.max())\n",
        "print(test_data.min(), test_data.max())\n",
        "print(labels)\n",
        "print(len(test_data), test_data[random.randrange(no_of_classes)].shape)\n",
        "# print(test_labels)\n",
        "\n",
        "img = np.array(cv2.imread(root_dir+'/random_image.png'))\n",
        "x = preprocess_input(img)\n",
        "cv2.imwrite(root_dir+'/p_random_image.png', x)\n",
        "p_img = np.array(cv2.imread(root_dir+'/p_random_image.png'))\n",
        "print(img.min(), img.max())\n",
        "print(p_img.min(), p_img.max())\n",
        "\n",
        "tempDisplay({\"img\": img, \"p_img\": p_img})\n",
        "\n",
        "# fig = plt.figure(figsize=(5, 5))\n",
        "# fig.add_subplot(1, 2, 1)\n",
        "# plt.imshow(img)\n",
        "# plt.axis('off')\n",
        "# fig.add_subplot(1, 2, 2)\n",
        "# plt.imshow(p_img)\n",
        "# plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuc0R4WqYsG5",
        "outputId": "b8a87330-1998-4675-d006-7e6ce86fd55f"
      },
      "outputs": [],
      "source": [
        "# Importing VGG16\n",
        "\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "base_model = VGG16(\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEH9fheYWQS1",
        "outputId": "6ce26642-04eb-4336-8fda-764a3f762029"
      },
      "outputs": [],
      "source": [
        "# Modifying the model\n",
        "\n",
        "avgpooling_layer_1 = GlobalAveragePooling2D()\n",
        "dropout_layer_1 = Dropout(0.2)\n",
        "dense_layer_1 = Dense(256, activation='relu')\n",
        "dense_layer_2 = Dense(256, activation='relu')\n",
        "dense_layer_3 = Dense(128, activation='relu')\n",
        "prediction_layer = Dense(no_of_classes, activation='softmax')\n",
        "\n",
        "character_model = models.Sequential([\n",
        "    base_model,\n",
        "    avgpooling_layer_1,\n",
        "    dense_layer_1,\n",
        "    dropout_layer_1,\n",
        "    dense_layer_2,\n",
        "    dense_layer_3,\n",
        "    prediction_layer,\n",
        "])\n",
        "character_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AHn2B-OzWSoN"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "\n",
        "# learning_rate = 0.0001\n",
        "# epochs=200\n",
        "# decay_rate = learning_rate / epochs\n",
        "# momentum = 0.8\n",
        "# custom_sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate)\n",
        "\n",
        "# custom_adam = Adam(learning_rate=0.001)\n",
        "# custom_adam = Adam(learning_rate=0.00003125)\n",
        "# custom_adam = Adam(learning_rate=0.00003125)\n",
        "\n",
        "character_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UaYjbLEsvPbK"
      },
      "outputs": [],
      "source": [
        "# Callbacks: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('vgg16_mmdb_400.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "# rlronp = ReduceLROnPlateau( monitor=\"val_accuracy\", factor=0.005,patience=1, verbose=1)\n",
        "rlronp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1,  min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, checkpoint, rlronp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8AAEvyuWUbb",
        "outputId": "65184146-bbea-428e-8376-5946207f3bc7"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = character_model.fit(\n",
        "    x=data,\n",
        "    y=labels,\n",
        "    epochs=200,\n",
        "    shuffle=True,\n",
        "    verbose='auto',\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "WAurau9upIvU",
        "outputId": "1ce39c14-a09a-4dc1-b256-6c309413b2a8"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(51) #change accordingly of epochs that run \n",
        "plt.plot(epochs, loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "5QvgxcL41nKt",
        "outputId": "51b32b26-ed28-47ea-d34f-c6b7f865d4d4"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "loss_train = history.history['accuracy']\n",
        "loss_val = history.history['val_accuracy']\n",
        "epochs = range(51) #change accordingly of epochs that run  \n",
        "plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "A49OXQuF6WWO"
      },
      "outputs": [],
      "source": [
        "character_model.save('vgg16_mmdb_400.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNw9e-RaOmDT",
        "outputId": "640aeecf-4ca6-4102-8bfa-f1f035947a98"
      },
      "outputs": [],
      "source": [
        "score = character_model.evaluate(test_data, test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW11h2nk5sfE",
        "outputId": "67875bc6-3c30-45e3-995a-25b75caf725a"
      },
      "outputs": [],
      "source": [
        "predictions = character_model.predict(test_data)\n",
        "print('Shape: {}'.format(predictions.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nFHX4CfoDA6Y",
        "outputId": "3fa71e4b-34e8-4753-b70b-12669ef6b590"
      },
      "outputs": [],
      "source": [
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_test,y_scores, classNames):\n",
        "    # y_test=np.argmax(y_test, axis=1)\n",
        "    # y_scores=np.argmax(y_scores, axis=1)\n",
        "    classes = len(classNames)\n",
        "    cm = confusion_matrix(y_test, y_scores)\n",
        "    # print(\"**** Confusion Matrix ****\")\n",
        "    # print(cm)\n",
        "    # print(\"**** Classification Report ****\")\n",
        "    # print(classification_report(y_test, y_scores, target_names=classNames))\n",
        "    con = np.zeros((classes,classes))\n",
        "    for x in range(classes):\n",
        "        for y in range(classes):\n",
        "            con[x,y] = cm[x,y]/np.sum(cm[x,:])\n",
        "\n",
        "    plt.figure(figsize=(100,100))\n",
        "    sns.set(font_scale=2.0) # for label size\n",
        "    df = sns.heatmap(con, annot=True,fmt='.2', cmap='Blues',xticklabels= classNames , yticklabels= classNames)\n",
        "    df.figure.savefig(\"image2.png\")\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(test_labels, predicted_classes, average=\"macro\")\n",
        "print('F1 score: %f' % f1)\n",
        "# confusion matrix\n",
        "plot_confusion_matrix(test_labels, predicted_classes, [str(i) for i in range(56)])\n",
        " \n",
        "# # kappa\n",
        "# kappa = cohen_kappa_score(test_labels, predicted_classes)\n",
        "# print('Cohens kappa: %f' % kappa)\n",
        "# # ROC AUC\n",
        "# auc = roc_auc_score(test_labels, predicted_classes, multi_class=\"ovr\")\n",
        "# print('ROC AUC: %f' % auc)\n",
        "# matrix = multilabel_confusion_matrix(test_labels, predicted_classes)\n",
        "# # for i in range(len(matrix)):\n",
        "# #   for j in range(len(matrix[0])):\n",
        "# #     print(matrix[i][j], end=\" \")\n",
        "# #   print(\"\")\n",
        "# print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g67CoDtE9_xI",
        "outputId": "7958e2a2-e4cb-4ffa-d7a1-8ee536a2f00c"
      },
      "outputs": [],
      "source": [
        "print(classification_report(test_labels, predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT6jf6d_5vRq",
        "outputId": "45a39459-4204-4c64-e2e6-44db38f32608"
      },
      "outputs": [],
      "source": [
        "for i in range(no_of_classes*test_size):\n",
        "  output_neuron = np.argmax(predictions[i])\n",
        "  print('Most active neuron: {} ({:.2f}%)'.format(\n",
        "      output_neuron,\n",
        "      100 * predictions[i][output_neuron]\n",
        "  ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "724EEP_5t3HZ",
        "outputId": "97f23083-4716-48c6-ccfd-038dcff0b135"
      },
      "outputs": [],
      "source": [
        "top1_correct = 0\n",
        "top1_incorrect = 0\n",
        "top5_correct = 0\n",
        "top5_incorrect = 0\n",
        "for i in range(no_of_classes*test_size):\n",
        "  s = set()\n",
        "  sorted_predictions = np.sort(predictions[i])[::-1]\n",
        "  for j in range(5):\n",
        "    x = list(np.where(predictions[i]==sorted_predictions[j]))[0][0]\n",
        "    s.add(x)\n",
        "  # print(list(s))\n",
        "  if test_labels[i] in s: top5_correct+=1\n",
        "  else: top5_incorrect+=1\n",
        "  if test_labels[i] == np.argmax(predictions[i]): top1_correct+=1\n",
        "  else: top1_incorrect+=1\n",
        "\n",
        "print('Top-1 Accuracy: ', (top1_correct*100)/(top1_correct+top1_incorrect))\n",
        "print('Top-5 Accuracy: ', (top5_correct*100)/(top5_correct+top5_incorrect))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHjucCYxVMAP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
